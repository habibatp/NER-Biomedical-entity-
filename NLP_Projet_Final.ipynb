{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5e47b82132ae45c5a7885549bd129481": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aa01a4354a1a40b1a3e43d71824f4f23",
              "IPY_MODEL_83d7aea1126043a1a633895d7dee6b33",
              "IPY_MODEL_3ddd05b58b354b48a78c5d3dff8eb5ed"
            ],
            "layout": "IPY_MODEL_c3008be2e9fd45dea255457984ca5c07"
          }
        },
        "aa01a4354a1a40b1a3e43d71824f4f23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b89d949cd6fa4a9e8c5f707d49d4d639",
            "placeholder": "​",
            "style": "IPY_MODEL_2305a10f125947f6b4e2c5ca59125da2",
            "value": "config.json: 100%"
          }
        },
        "83d7aea1126043a1a633895d7dee6b33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_138925f6cf354a2492760073fd4f3360",
            "max": 313,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_328a33d62d8840a388ce191626d751fa",
            "value": 313
          }
        },
        "3ddd05b58b354b48a78c5d3dff8eb5ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b4ab68e00504436ac6648f7398a164f",
            "placeholder": "​",
            "style": "IPY_MODEL_22a2387e2eb74876ae7ca82ad0acc3a4",
            "value": " 313/313 [00:00&lt;00:00, 12.0kB/s]"
          }
        },
        "c3008be2e9fd45dea255457984ca5c07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b89d949cd6fa4a9e8c5f707d49d4d639": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2305a10f125947f6b4e2c5ca59125da2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "138925f6cf354a2492760073fd4f3360": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "328a33d62d8840a388ce191626d751fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4b4ab68e00504436ac6648f7398a164f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22a2387e2eb74876ae7ca82ad0acc3a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24a722f799014450ab2f6e029a0dd2ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_56dac657eba44020aac66e44f23b9685",
              "IPY_MODEL_022b3f98e8624576a99b191c29e2c158",
              "IPY_MODEL_6384df2a6fe74f07950afb71f3638984"
            ],
            "layout": "IPY_MODEL_d8d3ea612f6f4773b6d4b1e024744c85"
          }
        },
        "56dac657eba44020aac66e44f23b9685": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_541b25b3f4924e009e1701fb9aa9d38f",
            "placeholder": "​",
            "style": "IPY_MODEL_bc6c8426bd9a4be692574f88f6684335",
            "value": "vocab.txt: 100%"
          }
        },
        "022b3f98e8624576a99b191c29e2c158": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_545e966959ed4a1a93ee6454e7c627d8",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6320a4fb998540119f7be776b4c2c6b1",
            "value": 213450
          }
        },
        "6384df2a6fe74f07950afb71f3638984": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d18369616244492a74220e9917a000b",
            "placeholder": "​",
            "style": "IPY_MODEL_3fdaf3bbcc5341fca341cf4fefcce10c",
            "value": " 213k/213k [00:00&lt;00:00, 2.91MB/s]"
          }
        },
        "d8d3ea612f6f4773b6d4b1e024744c85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "541b25b3f4924e009e1701fb9aa9d38f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc6c8426bd9a4be692574f88f6684335": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "545e966959ed4a1a93ee6454e7c627d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6320a4fb998540119f7be776b4c2c6b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8d18369616244492a74220e9917a000b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fdaf3bbcc5341fca341cf4fefcce10c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install biopython"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYNljYvJTxac",
        "outputId": "d81fb155-51bc-444d-f56e-55ccf12a0934"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting biopython\n",
            "  Downloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from biopython) (2.0.2)\n",
            "Downloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m179.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: biopython\n",
            "Successfully installed biopython-1.85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LG6wWZ4xRzuE",
        "outputId": "4f110272-cb56-45c9-94ef-6e13677f8eb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔎 Recherche en cours : human diseases\n",
            "🔎 Recherche en cours : disease symptoms\n",
            "🔎 Recherche en cours : human gene\n",
            "🔎 Recherche en cours : human protein\n",
            "✅ Corpus médical enregistré dans 'corpus_medical.csv'\n"
          ]
        }
      ],
      "source": [
        "from Bio import Entrez\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# ✅ Identifiant requis pour utiliser l'API de la NCBI\n",
        "Entrez.email = \"amizmizhabiba6@gmail.com\"  # Remplace par ton vrai email\n",
        "\n",
        "# ✅ Fonction pour interroger PubMed\n",
        "def get_pubmed_abstracts(query, max_results=80):\n",
        "    handle = Entrez.esearch(db=\"pubmed\", term=query, retmax=max_results)\n",
        "    record = Entrez.read(handle)\n",
        "    ids = record[\"IdList\"]\n",
        "\n",
        "    articles = []\n",
        "    for pubmed_id in ids:\n",
        "        try:\n",
        "            fetch_handle = Entrez.efetch(db=\"pubmed\", id=pubmed_id, rettype=\"abstract\", retmode=\"text\")\n",
        "            abstract = fetch_handle.read()\n",
        "            articles.append((pubmed_id, abstract))\n",
        "            time.sleep(0.5)  # Pour éviter de surcharger l’API\n",
        "        except Exception as e:\n",
        "            print(f\"Erreur pour l'ID {pubmed_id} : {e}\")\n",
        "    return articles\n",
        "\n",
        "# ✅ Requêtes associées aux catégories médicales\n",
        "queries = {\n",
        "    \"Disease\": \"human diseases\",\n",
        "    \"Symptom\": \"disease symptoms\",\n",
        "    \"Gene\": \"human gene\",\n",
        "    \"Protein\": \"human protein\"\n",
        "}\n",
        "\n",
        "# ✅ Extraction des données\n",
        "data = []\n",
        "\n",
        "for category, query in queries.items():\n",
        "    print(f\"🔎 Recherche en cours : {query}\")\n",
        "    articles = get_pubmed_abstracts(query, max_results=80)\n",
        "    for pmid, abstract in articles:\n",
        "        data.append({\"PMID\": pmid, \"Category\": category, \"Abstract\": abstract.strip()})\n",
        "\n",
        "# ✅ Enregistrement dans un fichier CSV\n",
        "df = pd.DataFrame(data)\n",
        "df.to_csv(\"corpus_medical.csv\", index=False)\n",
        "print(\"✅ Corpus médical enregistré dans 'corpus_medical.csv'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Compter directement depuis le DataFrame df\n",
        "count_by_category = df['Category'].value_counts()\n",
        "print(\"📊 Nombre de corpus par catégorie :\")\n",
        "print(count_by_category)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOKrOzU9T-CG",
        "outputId": "884c509b-8eb0-4326-c5b9-25145ea1c400"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Nombre de corpus par catégorie :\n",
            "Category\n",
            "Disease    80\n",
            "Symptom    80\n",
            "Gene       80\n",
            "Protein    80\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqaFkTwwUvb7",
        "outputId": "43d2e996-6016-48d1-b48b-c9ede97d4699"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "# Stopwords anglais de base + adverbes courants ajoutés manuellement\n",
        "stop_words = set([\n",
        "    \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\",\n",
        "    \"are\", \"aren't\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\",\n",
        "    \"between\", \"both\", \"but\", \"by\", \"could\", \"couldn't\", \"did\", \"didn't\", \"do\", \"does\",\n",
        "    \"doesn't\", \"doing\", \"don't\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\",\n",
        "    \"had\", \"hadn't\", \"has\", \"hasn't\", \"have\", \"haven't\", \"having\", \"he\", \"he'd\", \"he'll\",\n",
        "    \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\",\n",
        "    \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"isn't\", \"it\",\n",
        "    \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"mustn't\", \"my\", \"myself\",\n",
        "    \"no\", \"nor\", \"not\", \"of\", \"off\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\",\n",
        "    \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"shan't\", \"she\", \"she'd\", \"she'll\",\n",
        "    \"she's\", \"should\", \"shouldn't\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\",\n",
        "    \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\",\n",
        "    \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\",\n",
        "    \"under\", \"until\", \"up\", \"very\", \"was\", \"wasn't\", \"we\", \"we'd\", \"we'll\", \"we're\",\n",
        "    \"we've\", \"were\", \"weren't\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\",\n",
        "    \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"won't\", \"would\",\n",
        "    \"wouldn't\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\",\n",
        "    \"yourself\", \"yourselves\",\n",
        "\n",
        "    # Adverbes courants ajoutés\n",
        "    \"furthermore\", \"additionally\", \"however\", \"moreover\", \"nevertheless\",\n",
        "    \"thus\", \"therefore\", \"hence\", \"indeed\", \"still\", \"nonetheless\",\n",
        "    \"eventually\", \"usually\", \"generally\", \"specifically\", \"particularly\",\n",
        "    \"simply\", \"quickly\", \"slowly\", \"rapidly\", \"always\", \"sometimes\",\n",
        "    \"often\", \"rarely\", \"seldom\", \"hardly\", \"nearly\", \"barely\", \"easily\"\n",
        "])\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
        "    tokens = text.split()\n",
        "    tokens = [t for t in tokens if t not in stop_words]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Fichier des gènes\n",
        "gene_file = \"/content/drive/MyDrive/hafsa_nlp_projet/unique_gene_symbols.txt\"\n",
        "with open(gene_file, \"r\", encoding=\"utf-8\") as f:\n",
        "    gene_list = set(line.strip().upper() for line in f if line.strip())\n",
        "\n",
        "def extract_genes(text, gene_set):\n",
        "    tokens = re.findall(r'\\b\\w+\\b', text.upper())\n",
        "    return {token for token in tokens if token in gene_set and token.lower() not in stop_words}\n",
        "\n",
        "# Fichier des protéines\n",
        "protein_file = \"/content/drive/MyDrive/hafsa_nlp_projet/noms_proteines.txt\"\n",
        "with open(protein_file, \"r\", encoding=\"utf-8\") as f:\n",
        "    protein_names = set(line.strip().lower() for line in f if line.strip())\n",
        "\n",
        "def extract_proteins(text):\n",
        "    valid = set()\n",
        "    matches1 = re.findall(r'\\bprotein\\s+(\\w+)', text, re.IGNORECASE)\n",
        "    matches2 = re.findall(r'(\\w+)\\s+protein\\b', text, re.IGNORECASE)\n",
        "    for m in matches1 + matches2:\n",
        "        if m.lower() not in stop_words:\n",
        "            valid.add(m.lower())\n",
        "    from_list = {p for p in protein_names if p in text.lower() and p not in stop_words}\n",
        "    return valid.union(from_list)\n",
        "\n",
        "# Fichier des maladies\n",
        "keywords = [\"disease\", \"cancer\", \"disorder\", \"syndrome\", \"infection\", \"illness\", \"condition\",\n",
        "            \"injury\", \"tumor\", \"tumour\", \"carcinoma\", \"neoplasm\", \"pathology\", \"autoimmune\",\n",
        "            \"inflammatory\", \"genetic\", \"viral\", \"bacterial\", \"chronic\", \"arthritis\", \"diabetes\"]\n",
        "disease_pattern = re.compile(r\"\\b(?:%s)\\b\" % \"|\".join(re.escape(k) for k in keywords), re.IGNORECASE)\n",
        "def extract_diseases(text):\n",
        "    return {m for m in disease_pattern.findall(text) if m.lower() not in stop_words}\n",
        "\n",
        "# Fichier des symptômes\n",
        "symptom_file = \"/content/drive/MyDrive/hafsa_nlp_projet/symptoms_list_merged.txt\"\n",
        "with open(symptom_file, \"r\", encoding=\"utf-8\") as f:\n",
        "    symptoms = set(line.strip().lower() for line in f if line.strip())\n",
        "\n",
        "def extract_symptoms(text):\n",
        "    return {s for s in symptoms if s in text.lower() and s not in stop_words}\n"
      ],
      "metadata": {
        "id": "qVA-LzUqXT3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Charger les abstracts\n",
        "df = pd.read_csv(\"/content/corpus_medical.csv\")\n",
        "\n",
        "# Vérifie qu'il y a bien une colonne \"abstract\"\n",
        "if \"Abstract\" not in df.columns:\n",
        "    raise ValueError(\"Le fichier doit contenir une colonne 'abstract'.\")\n",
        "\n",
        "# Appliquer le nettoyage + extraction des entités à chaque ligne\n",
        "df[\"cleaned\"] = df[\"Abstract\"].apply(clean_text)\n",
        "df[\"genes\"] = df[\"cleaned\"].apply(lambda text: list(extract_genes(text, gene_list)))\n",
        "df[\"proteins\"] = df[\"cleaned\"].apply(extract_proteins)\n",
        "df[\"diseases\"] = df[\"cleaned\"].apply(extract_diseases)\n",
        "df[\"symptoms\"] = df[\"cleaned\"].apply(extract_symptoms)\n",
        "\n",
        "# Sauvegarder dans un nouveau fichier CSV\n",
        "df.to_csv(\"/content/abstracts07_06_annotated_custom.csv\", index=False)\n",
        "\n",
        "print(\"✅ Annotation terminée. Résultat enregistré dans 'abstracts_annotated_custom.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Hm0xVHPXTz-",
        "outputId": "48e3e1d7-a5bf-4fd0-b5df-fc68e5fff682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Annotation terminée. Résultat enregistré dans 'abstracts_annotated_custom.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "####\n",
        "import pandas as pd\n",
        "import ast\n",
        "import re\n",
        "\n",
        "# Charger les données\n",
        "df = pd.read_csv(\"/content/abstracts07_06_annotated_custom.csv\")\n",
        "\n",
        "# Fonction de transformation en BIO\n",
        "def annotate_bio(text, gene_list, protein_list, disease_list, symptom_list):\n",
        "    words = text.split()\n",
        "    labels = [\"O\"] * len(words)\n",
        "\n",
        "    # Fusionner toutes les entités avec leur label\n",
        "    entity_map = []\n",
        "    for term in gene_list:\n",
        "        entity_map.append((term.lower(), \"GENE\"))\n",
        "    for term in protein_list:\n",
        "        entity_map.append((term.lower(), \"PROTEIN\"))\n",
        "    for term in disease_list:\n",
        "        entity_map.append((term.lower(), \"DISEASE\"))\n",
        "    for term in symptom_list:\n",
        "        entity_map.append((term.lower(), \"SYMPTOM\"))\n",
        "\n",
        "    # Annoter le texte mot à mot\n",
        "    for entity, label in entity_map:\n",
        "        entity_words = entity.split()\n",
        "        entity_len = len(entity_words)\n",
        "\n",
        "        for i in range(len(words) - entity_len + 1):\n",
        "            window = words[i:i+entity_len]\n",
        "            if [w.lower() for w in window] == entity_words:\n",
        "                labels[i] = f\"B-{label}\"\n",
        "                for j in range(1, entity_len):\n",
        "                    labels[i+j] = f\"I-{label}\"\n",
        "\n",
        "    return list(zip(words, labels))\n",
        "\n",
        "# Fonction utilitaire pour transformer les chaînes en listes\n",
        "def safe_list(val):\n",
        "    if pd.isna(val) or val == '':\n",
        "        return []\n",
        "    if isinstance(val, list):\n",
        "        return val\n",
        "    try:\n",
        "        return ast.literal_eval(val)\n",
        "    except:\n",
        "        return []\n",
        "\n",
        "# Application à tout le DataFrame\n",
        "bio_data = []\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "    text = row['Abstract']\n",
        "    genes = safe_list(row.get(\"genes\", []))\n",
        "    proteins = safe_list(row.get(\"proteins\", []))\n",
        "    diseases = safe_list(row.get(\"diseases\", []))\n",
        "    symptoms = safe_list(row.get(\"symptoms\", []))\n",
        "\n",
        "    bio_tokens = annotate_bio(text, genes, proteins, diseases, symptoms)\n",
        "\n",
        "    for word, label in bio_tokens:\n",
        "        bio_data.append({\n",
        "            \"token\": word,\n",
        "            \"label\": label,\n",
        "            \"abstract_id\": idx\n",
        "        })\n",
        "\n",
        "# Sauvegarde en CSV\n",
        "bio_df = pd.DataFrame(bio_data)\n",
        "bio_df.to_csv(\"/content/abstracts_bio_format.csv\", index=False)\n",
        "\n",
        "print(\"✅ Fichier BIO généré : /content/abstracts_bio_format.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCm-RmmCXiMA",
        "outputId": "d463e7ee-d1be-4063-d820-2566810655e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fichier BIO généré : /content/abstracts_bio_format.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Charger le fichier BIO\n",
        "bio_df = pd.read_csv(\"/content/abstracts_bio_format.csv\")\n",
        "\n",
        "# Compter les occurrences de chaque label\n",
        "label_counts = bio_df['label'].value_counts()\n",
        "\n",
        "# Afficher les résultats\n",
        "print(\"📊 Nombre d'occurrences par label :\")\n",
        "print(label_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zN3DmBXOehwg",
        "outputId": "9ddade7d-4362-4625-b73a-8141f15fee98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Nombre d'occurrences par label :\n",
            "label\n",
            "O            137750\n",
            "B-DISEASE      1084\n",
            "B-PROTEIN       853\n",
            "B-GENE          349\n",
            "I-PROTEIN        66\n",
            "B-SYMPTOM        30\n",
            "I-SYMPTOM         3\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/abstracts07_06_annotated_custom.csv\")\n",
        "print(df.columns.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3N8PFAsXiIm",
        "outputId": "bd8a65fc-cf9e-4e7b-f257-79564b7d5064"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PMID', 'Category', 'Abstract', 'cleaned', 'genes', 'proteins', 'diseases', 'symptoms']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Charger les annotations\n",
        "df = pd.read_csv(\"/content/abstracts07_06_annotated_custom.csv\")\n",
        "\n",
        "# Initialiser les compteurs\n",
        "total_genes = 0\n",
        "total_proteins = 0\n",
        "total_diseases = 0\n",
        "total_symptoms = 0\n",
        "\n",
        "# Fonction pour compter les entités dans une cellule\n",
        "def count_entities(cell):\n",
        "    if pd.isna(cell) or cell.strip() == \"\":\n",
        "        return 0\n",
        "    return len(cell.split(','))\n",
        "\n",
        "# Compter pour chaque ligne\n",
        "for _, row in df.iterrows():\n",
        "    total_genes += count_entities(row['genes'])\n",
        "    total_proteins += count_entities(row['proteins'])\n",
        "    total_diseases += count_entities(row['diseases'])\n",
        "    total_symptoms += count_entities(row['symptoms'])\n",
        "\n",
        "# Résultats\n",
        "print(\"🧬 Nombre total de gènes :\", total_genes)\n",
        "print(\"🧪 Nombre total de protéines :\", total_proteins)\n",
        "print(\"🦠 Nombre total de maladies :\", total_diseases)\n",
        "print(\"🤒 Nombre total de symptômes :\", total_symptoms)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQflD1EIXiG-",
        "outputId": "cf718d44-2cd8-4ef9-f266-77f8d0f4feda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧬 Nombre total de gènes : 458\n",
            "🧪 Nombre total de protéines : 815\n",
            "🦠 Nombre total de maladies : 630\n",
            "🤒 Nombre total de symptômes : 331\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Charger le fichier original\n",
        "df = pd.read_csv(\"/content/abstracts07_06_annotated_custom.csv\")\n",
        "\n",
        "# 80% entraînement, 10% validation, 10% test\n",
        "train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
        "\n",
        "# Sauvegarder les splits\n",
        "train_df.to_csv(\"/content/abstracts07_06_train.csv\", index=False)\n",
        "val_df.to_csv(\"/content/abstracts07_06_val.csv\", index=False)\n",
        "test_df.to_csv(\"/content/abstracts07_06_test.csv\", index=False)\n",
        "\n",
        "print(f\"✅ Split terminé :\")\n",
        "print(f\"- Entraînement : {len(train_df)} lignes\")\n",
        "print(f\"- Validation   : {len(val_df)} lignes\")\n",
        "print(f\"- Test         : {len(test_df)} lignes\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZ-m05bwXiEu",
        "outputId": "3db3c731-dc7d-4941-bf28-cb84fcb8b14c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Split terminé :\n",
            "- Entraînement : 256 lignes\n",
            "- Validation   : 32 lignes\n",
            "- Test         : 32 lignes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Premiere Model"
      ],
      "metadata": {
        "id": "l_0pS5TLUN68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"/content/abstracts07_06_train.csv\")\n",
        "val_df   = pd.read_csv(\"/content/abstracts07_06_val.csv\")\n",
        "test_df  = pd.read_csv(\"/content/abstracts07_06_test.csv\")\n"
      ],
      "metadata": {
        "id": "YsKvEcWoXiC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pS2lR58hJyi",
        "outputId": "8e4395e9-f816-4535-b302-30e5aed0cf77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import ast\n",
        "\n",
        "# Download 'punkt' for word_tokenize (already done, but good practice to keep)\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Download the specific 'punkt_tab' resource mentioned in the error\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "\n",
        "# 📌 Fonction principale pour annotation BIO\n",
        "def annotate_bio(df, output_path):\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as fout:\n",
        "        for _, row in df.iterrows():\n",
        "            abstract = row['cleaned']  # ✅ colonne contenant le texte nettoyé\n",
        "\n",
        "            # Assurez-vous que la colonne 'cleaned' n'est pas vide ou None\n",
        "            if pd.isna(abstract) or abstract.strip() == \"\":\n",
        "                 continue # Ignore les lignes sans texte nettoyé\n",
        "\n",
        "            try:\n",
        "                # Utiliser un ensemble vide si la colonne n'existe pas\n",
        "                # ou si l'évaluation échoue\n",
        "                genes = set(ast.literal_eval(row.get('genes', '[]')))\n",
        "                proteins = set(ast.literal_eval(row.get('proteins', '[]')))\n",
        "                diseases = set(ast.literal_eval(row.get('diseases', '[]')))\n",
        "                symptoms = set(ast.literal_eval(row.get('symptoms', '[]')))\n",
        "            except Exception as e:\n",
        "                print(f\"Erreur parsing à la ligne {row.name} : {e}\")\n",
        "                continue\n",
        "\n",
        "            # Gérer les cas où abstract pourrait être None ou non-string\n",
        "            if not isinstance(abstract, str):\n",
        "                 print(f\"Ligne {row.name} a un type d'abstract inattendu: {type(abstract)}\")\n",
        "                 continue\n",
        "\n",
        "\n",
        "            tokens = word_tokenize(abstract)\n",
        "\n",
        "            for token in tokens:\n",
        "                tag = \"O\"\n",
        "                token_lower = token.lower()\n",
        "                token_upper = token.upper()\n",
        "\n",
        "                # Itérer sur les ensembles d'entités\n",
        "                if token_upper in genes:\n",
        "                    tag = \"B-GENE\"\n",
        "                elif token_lower in proteins:\n",
        "                    tag = \"B-PROTEIN\"\n",
        "                elif token_lower in diseases:\n",
        "                    tag = \"B-DISEASE\"\n",
        "                elif token_lower in symptoms:\n",
        "                    tag = \"B-SYMPTOM\"\n",
        "\n",
        "                fout.write(f\"{token} {tag}\\n\")\n",
        "            fout.write(\"\\n\")\n",
        "\n",
        "    print(f\"✅ Fichier BIO sauvegardé dans : {output_path}\")\n",
        "\n",
        "# 🔄 Chargement des fichiers\n",
        "train_df = pd.read_csv(\"/content/abstracts07_06_train.csv\")\n",
        "val_df   = pd.read_csv(\"/content/abstracts07_06_val.csv\")\n",
        "test_df  = pd.read_csv(\"/content/abstracts07_06_test.csv\")\n",
        "\n",
        "# 📝 Application\n",
        "annotate_bio(train_df, \"/content/abstracts07_06_bio_train.bio\")\n",
        "annotate_bio(val_df, \"/content/abstracts07_06_bio_val.bio\")\n",
        "annotate_bio(test_df, \"/content/abstracts07_06_bio_test.bio\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7BM7V7Ih5nm",
        "outputId": "907e9c55-be37-4c86-87fd-a0f6df5bd76d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fichier BIO sauvegardé dans : /content/abstracts07_06_bio_train.bio\n",
            "✅ Fichier BIO sauvegardé dans : /content/abstracts07_06_bio_val.bio\n",
            "✅ Fichier BIO sauvegardé dans : /content/abstracts07_06_bio_test.bio\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Elle ignore les tokens \"O\" dans les labels pendant l'entraînement.\n",
        "\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# 📌 Modèle utilisé (BioBERT)\n",
        "model_name = \"dmis-lab/biobert-base-cased-v1.1\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# 🏷️ Étiquettes\n",
        "label_list = ['O', 'B-GENE', 'B-PROTEIN', 'B-DISEASE', 'B-SYMPTOM']\n",
        "label2id = {label: i for i, label in enumerate(label_list)}\n",
        "id2label = {i: label for label, i in label2id.items()}\n",
        "\n",
        "\n",
        "# 📄 Lire un fichier BIO et l'organiser par phrase\n",
        "def read_bio_file(filepath):\n",
        "    sentences = []\n",
        "    labels = []\n",
        "    current_tokens = []\n",
        "    current_labels = []\n",
        "\n",
        "    with open(filepath, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            if line.strip() == '':\n",
        "                if current_tokens:\n",
        "                    sentences.append(current_tokens)\n",
        "                    labels.append(current_labels)\n",
        "                    current_tokens = []\n",
        "                    current_labels = []\n",
        "            else:\n",
        "                splits = line.strip().split()\n",
        "                if len(splits) == 2:\n",
        "                    token, tag = splits\n",
        "                    current_tokens.append(token)\n",
        "                    current_labels.append(tag)\n",
        "\n",
        "        # Ajouter la dernière phrase si non vide\n",
        "        if current_tokens:\n",
        "            sentences.append(current_tokens)\n",
        "            labels.append(current_labels)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "\n",
        "# ✂️ Tokenisation + alignement des labels avec gestion du max_length\n",
        "#    et exclusion des tokens \"O\" (ignorés avec -100)\n",
        "def tokenize_and_align(sentences, tags, tokenizer):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        sentences,\n",
        "        is_split_into_words=True,\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        padding=\"max_length\",\n",
        "        return_tensors=None\n",
        "    )\n",
        "\n",
        "    aligned_labels = []\n",
        "    for i, label in enumerate(tags):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            elif word_idx != previous_word_idx:\n",
        "                tag = label[word_idx]\n",
        "                label_ids.append(label2id[tag] if tag != \"O\" else -100)\n",
        "            else:\n",
        "                label_ids.append(-100)\n",
        "            previous_word_idx = word_idx\n",
        "\n",
        "        aligned_labels.append(label_ids)\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = aligned_labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "\n",
        "# 📁 Préparer un Dataset HuggingFace depuis un fichier BIO\n",
        "def prepare_dataset_from_bio(filepath):\n",
        "    sents, tags = read_bio_file(filepath)\n",
        "    tokenized = tokenize_and_align(sents, tags, tokenizer)\n",
        "    return Dataset.from_dict(tokenized)\n",
        "\n",
        "\n",
        "# ✅ Créer les datasets avec les bons fichiers\n",
        "train_dataset = prepare_dataset_from_bio(\"/content/abstracts07_06_bio_train.bio\")\n",
        "val_dataset   = prepare_dataset_from_bio(\"/content/abstracts07_06_bio_val.bio\")\n",
        "test_dataset  = prepare_dataset_from_bio(\"/content/abstracts07_06_bio_test.bio\")\n",
        "\n",
        "# 🔍 Vérification\n",
        "print(\"✅ Datasets créés :\")\n",
        "print(\"Exemple train_dataset :\")\n",
        "print(train_dataset[0])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257,
          "referenced_widgets": [
            "5e47b82132ae45c5a7885549bd129481",
            "aa01a4354a1a40b1a3e43d71824f4f23",
            "83d7aea1126043a1a633895d7dee6b33",
            "3ddd05b58b354b48a78c5d3dff8eb5ed",
            "c3008be2e9fd45dea255457984ca5c07",
            "b89d949cd6fa4a9e8c5f707d49d4d639",
            "2305a10f125947f6b4e2c5ca59125da2",
            "138925f6cf354a2492760073fd4f3360",
            "328a33d62d8840a388ce191626d751fa",
            "4b4ab68e00504436ac6648f7398a164f",
            "22a2387e2eb74876ae7ca82ad0acc3a4",
            "24a722f799014450ab2f6e029a0dd2ec",
            "56dac657eba44020aac66e44f23b9685",
            "022b3f98e8624576a99b191c29e2c158",
            "6384df2a6fe74f07950afb71f3638984",
            "d8d3ea612f6f4773b6d4b1e024744c85",
            "541b25b3f4924e009e1701fb9aa9d38f",
            "bc6c8426bd9a4be692574f88f6684335",
            "545e966959ed4a1a93ee6454e7c627d8",
            "6320a4fb998540119f7be776b4c2c6b1",
            "8d18369616244492a74220e9917a000b",
            "3fdaf3bbcc5341fca341cf4fefcce10c"
          ]
        },
        "id": "wy8oacm8hAB9",
        "outputId": "45a3e801-14ee-47c2-8969-60e308911336"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/313 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e47b82132ae45c5a7885549bd129481"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "24a722f799014450ab2f6e029a0dd2ec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Datasets créés :\n",
            "Exemple train_dataset :\n",
            "{'input_ids': [101, 122, 24443, 22572, 4060, 2496, 1161, 17881, 1571, 14516, 1643, 122, 16222, 1571, 3236, 23117, 22997, 9465, 1275, 7393, 1545, 179, 170, 2599, 17881, 1571, 3236, 23117, 22997, 174, 16091, 1830, 17881, 1571, 1336, 1695, 15139, 17599, 2087, 7535, 2386, 1596, 11140, 3919, 4164, 6099, 1751, 11432, 2022, 3023, 3507, 17960, 20942, 181, 1182, 177, 122, 11437, 1162, 194, 123, 192, 1358, 194, 124, 11019, 1186, 194, 125, 181, 19009, 192, 126, 195, 22235, 187, 127, 175, 14429, 193, 128, 5871, 1186, 187, 129, 2351, 1869, 122, 1278, 22759, 5144, 1161, 2657, 2755, 1131, 15449, 2118, 6745, 11964, 1477, 5144, 1161, 2853, 12844, 4807, 21718, 2605, 16198, 8117, 1278, 1470, 2332, 2364, 2657, 2755, 1129, 23784, 2118, 6087, 1545, 1580, 5144, 1161, 2853, 3653, 13347, 1654, 1148, 2657, 2057, 5144, 6420, 185, 1742, 1704, 2704, 1129, 23784, 2118, 1620, 1604, 24239, 5144, 1161, 4828, 4134, 17801, 24606, 24766, 1545, 1580, 1580, 1559, 19207, 3254, 123, 2853, 12844, 4807, 21718, 2605, 16198, 8117, 1278, 1470, 2332, 2364, 2657, 2755, 1129, 23784, 2118, 6087, 1545, 1580, 5144, 1161, 4828, 4134, 11437, 2254, 6094, 11964, 1495, 17594, 14746, 3254, 124, 2853, 12844, 4807, 21718, 2605, 16198, 8117, 1278, 1470, 2332, 2364, 2657, 2755, 1129, 23784, 2118, 6087, 1545, 1580, 5144, 1161, 4828, 4134, 192, 20257, 1182, 7629, 23124, 19207, 3254, 125, 2853, 12844, 4807, 21718, 2605, 16198, 8117, 1278, 1470, 2332, 2364, 2657, 2755, 1129, 23784, 2118, 6087, 1545, 1580, 5144, 1161, 4828, 4134, 172, 1183, 1183, 3457, 14402, 13601, 5048, 1358, 172, 1179, 126, 5144, 6420, 185, 1742, 2057, 3653, 1654, 13347, 1129, 23784, 2118, 6087, 1559, 1475, 5144, 1161, 4828, 4134, 17128, 1559, 22392, 1571, 10973, 1580, 19207, 3254, 127, 5144, 6420, 185, 1742, 2057, 3653, 1654, 13347, 1129, 23784, 2118, 6087, 1559, 1475, 5144, 1161, 4828, 4134, 195, 22235, 16822, 1777, 1186, 16382, 1604, 1527, 19207, 3254, 128, 1278, 22759, 5144, 1161, 2657, 2755, 1131, 15449, 2118, 6745, 11964, 1477, 5144, 1161, 4828, 4134, 3262, 9650, 1813, 14491, 3254, 129, 2853, 12844, 4807, 21718, 2605, 16198, 8117, 1278, 1470, 2332, 2364, 2657, 2755, 1129, 23784, 2118, 6087, 1545, 1580, 5144, 1161, 4828, 4134, 5871, 1186, 14402, 13601, 5048, 1358, 172, 1179, 3582, 2793, 4265, 2819, 3023, 3507, 17960, 20942, 182, 26466, 174, 15792, 1161, 20942, 12976, 14844, 1444, 2967, 1775, 11432, 7951, 1954, 4069, 2960, 11137, 19648, 9117, 5871, 20900, 1116, 8010, 1654, 9100, 2609, 11106, 4265, 10900, 3268, 2361, 4884, 1176, 1842, 1159, 25220, 21176, 6530, 4129, 3943, 186, 1643, 1665, 1197, 24034, 18890, 9100, 2609, 1877, 1496, 8087, 12864, 9517, 7623, 4675, 5420, 15139, 6099, 2616, 3903, 3442, 2967, 1775, 1768, 11432, 3023, 3507, 17960, 20942, 11774, 1834, 4134, 2898, 4433, 8010, 1116, 9100, 2609, 11106, 2686, 2025, 3014, 6099, 27349, 1665, 5190, 16026, 3442, 1982, 1606, 2526, 1359, 20866, 23743, 3204, 1714, 2063, 1439, 123, 11241, 2886, 17599, 2087, 7535, 2386, 1596, 11451, 6576, 7812, 22060, 1110, 12858, 1200, 7435, 1821, 1643, 17489, 11140, 2815, 3689, 1768, 23660, 1895, 15139, 11432, 3442, 12201, 17599, 2087, 7535, 2386, 1596, 11140, 3919, 4164, 3919, 4164, 3643, 19648, 11432, 2022, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 3, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 3, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 3, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seqeval\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vulcEccl319",
        "outputId": "d4e201e9-b5d6-4a9b-a51c-295f51efa346"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from seqeval) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=58e0ae9d41eb3d39f695bf09fb1c0dc94e601e6c398dfc83775a9cb2bf3c9623\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
        "import numpy as np\n",
        "from seqeval.metrics import classification_report, accuracy_score, f1_score\n",
        "\n",
        "# ✅ Charger le modèle pré-entraîné\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    \"dmis-lab/biobert-base-cased-v1.1\",\n",
        "    num_labels=len(label_list),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")\n",
        "\n",
        "# 📊 Métriques d’évaluation\n",
        "def compute_metrics(p):\n",
        "    preds = np.argmax(p.predictions, axis=2)\n",
        "    labels = p.label_ids\n",
        "\n",
        "    true_predictions = [\n",
        "        [id2label[p] for (p, l) in zip(pred, label) if l != -100]\n",
        "        for pred, label in zip(preds, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [id2label[l] for (p, l) in zip(pred, label) if l != -100]\n",
        "        for pred, label in zip(preds, labels)\n",
        "    ]\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(true_labels, true_predictions),\n",
        "        \"f1\": f1_score(true_labels, true_predictions),\n",
        "        \"report\": classification_report(true_labels, true_predictions, output_dict=False)\n",
        "    }\n",
        "\n",
        "# 🔧 Arguments d'entraînement\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./ner_biobert\",\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=4,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=50,\n",
        "    save_steps=500,\n",
        "    eval_steps=500,\n",
        "    save_total_limit=2,\n",
        ")\n",
        "\n",
        "# 🚀 Entraînement avec Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "3xUf0kDShAAA",
        "outputId": "8a531cf9-f8fc-41e9-db74-2254000d461f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-24-3145e7aac804>:51: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhafsaikram31\u001b[0m (\u001b[33mhafsaikram31-cadi-ayyad\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250609_102608-iucpzgxi</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/hafsaikram31-cadi-ayyad/huggingface/runs/iucpzgxi' target=\"_blank\">./ner_biobert</a></strong> to <a href='https://wandb.ai/hafsaikram31-cadi-ayyad/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/hafsaikram31-cadi-ayyad/huggingface' target=\"_blank\">https://wandb.ai/hafsaikram31-cadi-ayyad/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/hafsaikram31-cadi-ayyad/huggingface/runs/iucpzgxi' target=\"_blank\">https://wandb.ai/hafsaikram31-cadi-ayyad/huggingface/runs/iucpzgxi</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [128/128 01:42, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.560000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.173500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=128, training_loss=0.30564939603209496, metrics={'train_runtime': 117.4076, 'train_samples_per_second': 8.722, 'train_steps_per_second': 1.09, 'total_flos': 267575136092160.0, 'train_loss': 0.30564939603209496, 'epoch': 4.0})"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Évaluer le modèle sur le jeu de validation\n",
        "results = trainer.evaluate()\n",
        "\n",
        "# Affichage des métriques principales\n",
        "print(\"📊 Résultats de l'évaluation :\")\n",
        "print(f\"Accuracy : {results['eval_accuracy']:.4f}\")\n",
        "print(f\"F1-score : {results['eval_f1']:.4f}\")\n",
        "print(\"\\n📄 Rapport détaillé :\")\n",
        "print(results['eval_report'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "p6-sxTUug_7R",
        "outputId": "fafd90da-77c5-44f9-bd6a-5e17c7c35c0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4/4 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Résultats de l'évaluation :\n",
            "Accuracy : 0.9504\n",
            "F1-score : 0.9504\n",
            "\n",
            "📄 Rapport détaillé :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     DISEASE       0.98      0.97      0.97        94\n",
            "        GENE       0.88      0.98      0.93        45\n",
            "     PROTEIN       0.96      0.93      0.95       102\n",
            "     SYMPTOM       0.00      0.00      0.00         1\n",
            "\n",
            "   micro avg       0.95      0.95      0.95       242\n",
            "   macro avg       0.70      0.72      0.71       242\n",
            "weighted avg       0.95      0.95      0.95       242\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 📊 Évaluation sur le jeu de test\n",
        "test_results = trainer.evaluate(eval_dataset=test_dataset)\n",
        "\n",
        "# 📋 Affichage des métriques\n",
        "print(\"📊 Résultats sur le jeu de test :\")\n",
        "print(f\"Accuracy : {test_results['eval_accuracy']:.4f}\")\n",
        "print(f\"F1-score : {test_results['eval_f1']:.4f}\")\n",
        "print(\"\\n📄 Rapport détaillé :\")\n",
        "print(test_results['eval_report'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "emdAoT-xlb_5",
        "outputId": "f730ec3b-757e-44e1-8454-9134fa405fdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4/4 01:24]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Résultats sur le jeu de test :\n",
            "Accuracy : 0.9648\n",
            "F1-score : 0.9648\n",
            "\n",
            "📄 Rapport détaillé :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     DISEASE       0.97      1.00      0.99       101\n",
            "        GENE       0.91      0.94      0.92        52\n",
            "     PROTEIN       1.00      0.95      0.97        73\n",
            "     SYMPTOM       0.00      0.00      0.00         1\n",
            "\n",
            "   micro avg       0.96      0.96      0.96       227\n",
            "   macro avg       0.72      0.72      0.72       227\n",
            "weighted avg       0.96      0.96      0.96       227\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "source_dir = \"/content\"\n",
        "target_dir = \"/content/drive/MyDrive/NLP_dernier_modification_09_06\"\n",
        "\n",
        "# Créer le dossier cible s’il n’existe pas\n",
        "os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "# Parcourir tous les fichiers/dossiers dans /content sauf /content/drive\n",
        "for item in os.listdir(source_dir):\n",
        "    src_path = os.path.join(source_dir, item)\n",
        "    dst_path = os.path.join(target_dir, item)\n",
        "\n",
        "    if item == \"drive\":\n",
        "        continue  # ⚠️ Ignorer le dossier Google Drive\n",
        "\n",
        "    try:\n",
        "        if os.path.isdir(src_path):\n",
        "            shutil.copytree(src_path, dst_path, dirs_exist_ok=True)\n",
        "        else:\n",
        "            shutil.copy2(src_path, dst_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Erreur en copiant {item} : {e}\")\n",
        "\n",
        "print(f\"✅ Tous les fichiers (sauf /drive) ont été copiés vers : {target_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kUijvWmlb8f",
        "outputId": "433bad24-0bcf-485a-f97d-090b49d1387b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Tous les fichiers (sauf /drive) ont été copiés vers : /content/drive/MyDrive/NLP_dernier_modification_09_06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test d'abilation sur data"
      ],
      "metadata": {
        "id": "qPq3x1vpQ8Do"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Charger le fichier original\n",
        "df = pd.read_csv(\"/content/abstracts07_06_annotated_custom.csv\")\n",
        "\n",
        "# Différentes configurations à tester\n",
        "configurations = [\n",
        "    # (train%, val%, test%, nom)\n",
        "    (0.8, 0.1, 0.1, \"80_10_10\"),     # Original\n",
        "    (0.7, 0.15, 0.15, \"70_15_15\"),   # Plus équilibré\n",
        "    (0.9, 0.05, 0.05, \"90_5_5\"),     # Plus d'entraînement\n",
        "    (0.6, 0.2, 0.2, \"60_20_20\"),     # Plus de validation/test\n",
        "    (0.75, 0.125, 0.125, \"75_12.5_12.5\"), # Intermédiaire\n",
        "]\n",
        "\n",
        "print(f\"📊 Dataset total : {len(df)} lignes\\n\")\n",
        "\n",
        "for train_pct, val_pct, test_pct, name in configurations:\n",
        "    print(f\"🔄 Configuration {name} (Train: {train_pct:.1%}, Val: {val_pct:.1%}, Test: {test_pct:.1%})\")\n",
        "\n",
        "    # Premier split : train vs (val+test)\n",
        "    train_df, temp_df = train_test_split(df, test_size=(val_pct + test_pct), random_state=42)\n",
        "\n",
        "    # Deuxième split : val vs test\n",
        "    val_df, test_df = train_test_split(temp_df, test_size=(test_pct/(val_pct + test_pct)), random_state=42)\n",
        "\n",
        "    # Sauvegarder avec suffixe\n",
        "    train_df.to_csv(f\"/content/abstracts07_06_train_{name}.csv\", index=False)\n",
        "    val_df.to_csv(f\"/content/abstracts07_06_val_{name}.csv\", index=False)\n",
        "    test_df.to_csv(f\"/content/abstracts07_06_test_{name}.csv\", index=False)\n",
        "\n",
        "    print(f\"  ✅ Entraînement : {len(train_df)} lignes ({len(train_df)/len(df):.1%})\")\n",
        "    print(f\"  ✅ Validation   : {len(val_df)} lignes ({len(val_df)/len(df):.1%})\")\n",
        "    print(f\"  ✅ Test         : {len(test_df)} lignes ({len(test_df)/len(df):.1%})\")\n",
        "    print(f\"  📁 Fichiers sauvegardés avec suffixe '_{name}'\\n\")\n",
        "\n",
        "print(\"✅ Tous les splits terminés !\")\n",
        "print(\"\\nFichiers créés :\")\n",
        "for _, _, _, name in configurations:\n",
        "    print(f\"  - abstracts07_06_train_{name}.csv\")\n",
        "    print(f\"  - abstracts07_06_val_{name}.csv\")\n",
        "    print(f\"  - abstracts07_06_test_{name}.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PGc_RLxRA37",
        "outputId": "f614a0d7-8ac3-47bf-be15-c780f6498464"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Dataset total : 320 lignes\n",
            "\n",
            "🔄 Configuration 80_10_10 (Train: 80.0%, Val: 10.0%, Test: 10.0%)\n",
            "  ✅ Entraînement : 256 lignes (80.0%)\n",
            "  ✅ Validation   : 32 lignes (10.0%)\n",
            "  ✅ Test         : 32 lignes (10.0%)\n",
            "  📁 Fichiers sauvegardés avec suffixe '_80_10_10'\n",
            "\n",
            "🔄 Configuration 70_15_15 (Train: 70.0%, Val: 15.0%, Test: 15.0%)\n",
            "  ✅ Entraînement : 224 lignes (70.0%)\n",
            "  ✅ Validation   : 48 lignes (15.0%)\n",
            "  ✅ Test         : 48 lignes (15.0%)\n",
            "  📁 Fichiers sauvegardés avec suffixe '_70_15_15'\n",
            "\n",
            "🔄 Configuration 90_5_5 (Train: 90.0%, Val: 5.0%, Test: 5.0%)\n",
            "  ✅ Entraînement : 288 lignes (90.0%)\n",
            "  ✅ Validation   : 16 lignes (5.0%)\n",
            "  ✅ Test         : 16 lignes (5.0%)\n",
            "  📁 Fichiers sauvegardés avec suffixe '_90_5_5'\n",
            "\n",
            "🔄 Configuration 60_20_20 (Train: 60.0%, Val: 20.0%, Test: 20.0%)\n",
            "  ✅ Entraînement : 192 lignes (60.0%)\n",
            "  ✅ Validation   : 64 lignes (20.0%)\n",
            "  ✅ Test         : 64 lignes (20.0%)\n",
            "  📁 Fichiers sauvegardés avec suffixe '_60_20_20'\n",
            "\n",
            "🔄 Configuration 75_12.5_12.5 (Train: 75.0%, Val: 12.5%, Test: 12.5%)\n",
            "  ✅ Entraînement : 240 lignes (75.0%)\n",
            "  ✅ Validation   : 40 lignes (12.5%)\n",
            "  ✅ Test         : 40 lignes (12.5%)\n",
            "  📁 Fichiers sauvegardés avec suffixe '_75_12.5_12.5'\n",
            "\n",
            "✅ Tous les splits terminés !\n",
            "\n",
            "Fichiers créés :\n",
            "  - abstracts07_06_train_80_10_10.csv\n",
            "  - abstracts07_06_val_80_10_10.csv\n",
            "  - abstracts07_06_test_80_10_10.csv\n",
            "  - abstracts07_06_train_70_15_15.csv\n",
            "  - abstracts07_06_val_70_15_15.csv\n",
            "  - abstracts07_06_test_70_15_15.csv\n",
            "  - abstracts07_06_train_90_5_5.csv\n",
            "  - abstracts07_06_val_90_5_5.csv\n",
            "  - abstracts07_06_test_90_5_5.csv\n",
            "  - abstracts07_06_train_60_20_20.csv\n",
            "  - abstracts07_06_val_60_20_20.csv\n",
            "  - abstracts07_06_test_60_20_20.csv\n",
            "  - abstracts07_06_train_75_12.5_12.5.csv\n",
            "  - abstracts07_06_val_75_12.5_12.5.csv\n",
            "  - abstracts07_06_test_75_12.5_12.5.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### _90_5_5"
      ],
      "metadata": {
        "id": "Q6qgoe34VVx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import ast\n",
        "\n",
        "# Download 'punkt' for word_tokenize (already done, but good practice to keep)\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Download the specific 'punkt_tab' resource mentioned in the error\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "\n",
        "# 📌 Fonction principale pour annotation BIO\n",
        "def annotate_bio(df, output_path):\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as fout:\n",
        "        for _, row in df.iterrows():\n",
        "            abstract = row['cleaned']  # ✅ colonne contenant le texte nettoyé\n",
        "\n",
        "            # Assurez-vous que la colonne 'cleaned' n'est pas vide ou None\n",
        "            if pd.isna(abstract) or abstract.strip() == \"\":\n",
        "                 continue # Ignore les lignes sans texte nettoyé\n",
        "\n",
        "            try:\n",
        "                # Utiliser un ensemble vide si la colonne n'existe pas\n",
        "                # ou si l'évaluation échoue\n",
        "                genes = set(ast.literal_eval(row.get('genes', '[]')))\n",
        "                proteins = set(ast.literal_eval(row.get('proteins', '[]')))\n",
        "                diseases = set(ast.literal_eval(row.get('diseases', '[]')))\n",
        "                symptoms = set(ast.literal_eval(row.get('symptoms', '[]')))\n",
        "            except Exception as e:\n",
        "                print(f\"Erreur parsing à la ligne {row.name} : {e}\")\n",
        "                continue\n",
        "\n",
        "            # Gérer les cas où abstract pourrait être None ou non-string\n",
        "            if not isinstance(abstract, str):\n",
        "                 print(f\"Ligne {row.name} a un type d'abstract inattendu: {type(abstract)}\")\n",
        "                 continue\n",
        "\n",
        "\n",
        "            tokens = word_tokenize(abstract)\n",
        "\n",
        "            for token in tokens:\n",
        "                tag = \"O\"\n",
        "                token_lower = token.lower()\n",
        "                token_upper = token.upper()\n",
        "\n",
        "                # Itérer sur les ensembles d'entités\n",
        "                if token_upper in genes:\n",
        "                    tag = \"B-GENE\"\n",
        "                elif token_lower in proteins:\n",
        "                    tag = \"B-PROTEIN\"\n",
        "                elif token_lower in diseases:\n",
        "                    tag = \"B-DISEASE\"\n",
        "                elif token_lower in symptoms:\n",
        "                    tag = \"B-SYMPTOM\"\n",
        "\n",
        "                fout.write(f\"{token} {tag}\\n\")\n",
        "            fout.write(\"\\n\")\n",
        "\n",
        "    print(f\"✅ Fichier BIO sauvegardé dans : {output_path}\")\n",
        "\n",
        "# 🔄 Chargement des fichiers\n",
        "train_df = pd.read_csv(\"/content/abstracts07_06_train_90_5_5.csv\")\n",
        "val_df   = pd.read_csv(\"/content/abstracts07_06_val_90_5_5.csv\")\n",
        "test_df  = pd.read_csv(\"/content/abstracts07_06_test_90_5_5.csv\")\n",
        "\n",
        "# 📝 Application\n",
        "annotate_bio(train_df, \"/content/abstracts07_06_bio_train_90_5_5.bio\")\n",
        "annotate_bio(val_df, \"/content/abstracts07_06_bio_val_90_5_5.bio\")\n",
        "annotate_bio(test_df, \"/content/abstracts07_06_bio_test_90_5_5.bio\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCPZgwnPRdra",
        "outputId": "c6197d71-b567-4d15-a5cd-6bee8adb520d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fichier BIO sauvegardé dans : /content/abstracts07_06_bio_train_90_5_5.bio\n",
            "✅ Fichier BIO sauvegardé dans : /content/abstracts07_06_bio_val_90_5_5.bio\n",
            "✅ Fichier BIO sauvegardé dans : /content/abstracts07_06_bio_test_90_5_5.bio\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Elle ignore les tokens \"O\" dans les labels pendant l'entraînement.\n",
        "\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# 📌 Modèle utilisé (BioBERT)\n",
        "model_name = \"dmis-lab/biobert-base-cased-v1.1\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# 🏷️ Étiquettes\n",
        "label_list = ['O', 'B-GENE', 'B-PROTEIN', 'B-DISEASE', 'B-SYMPTOM']\n",
        "label2id = {label: i for i, label in enumerate(label_list)}\n",
        "id2label = {i: label for label, i in label2id.items()}\n",
        "\n",
        "\n",
        "# 📄 Lire un fichier BIO et l'organiser par phrase\n",
        "def read_bio_file(filepath):\n",
        "    sentences = []\n",
        "    labels = []\n",
        "    current_tokens = []\n",
        "    current_labels = []\n",
        "\n",
        "    with open(filepath, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            if line.strip() == '':\n",
        "                if current_tokens:\n",
        "                    sentences.append(current_tokens)\n",
        "                    labels.append(current_labels)\n",
        "                    current_tokens = []\n",
        "                    current_labels = []\n",
        "            else:\n",
        "                splits = line.strip().split()\n",
        "                if len(splits) == 2:\n",
        "                    token, tag = splits\n",
        "                    current_tokens.append(token)\n",
        "                    current_labels.append(tag)\n",
        "\n",
        "        # Ajouter la dernière phrase si non vide\n",
        "        if current_tokens:\n",
        "            sentences.append(current_tokens)\n",
        "            labels.append(current_labels)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "\n",
        "# ✂️ Tokenisation + alignement des labels avec gestion du max_length\n",
        "#    et exclusion des tokens \"O\" (ignorés avec -100)\n",
        "def tokenize_and_align(sentences, tags, tokenizer):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        sentences,\n",
        "        is_split_into_words=True,\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        padding=\"max_length\",\n",
        "        return_tensors=None\n",
        "    )\n",
        "\n",
        "    aligned_labels = []\n",
        "    for i, label in enumerate(tags):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            elif word_idx != previous_word_idx:\n",
        "                tag = label[word_idx]\n",
        "                label_ids.append(label2id[tag] if tag != \"O\" else -100)\n",
        "            else:\n",
        "                label_ids.append(-100)\n",
        "            previous_word_idx = word_idx\n",
        "\n",
        "        aligned_labels.append(label_ids)\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = aligned_labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "\n",
        "# 📁 Préparer un Dataset HuggingFace depuis un fichier BIO\n",
        "def prepare_dataset_from_bio(filepath):\n",
        "    sents, tags = read_bio_file(filepath)\n",
        "    tokenized = tokenize_and_align(sents, tags, tokenizer)\n",
        "    return Dataset.from_dict(tokenized)\n",
        "\n",
        "\n",
        "# ✅ Créer les datasets avec les bons fichiers\n",
        "train_dataset = prepare_dataset_from_bio(\"//content/abstracts07_06_bio_train_90_5_5.bio\")\n",
        "val_dataset   = prepare_dataset_from_bio(\"/content/abstracts07_06_bio_val_90_5_5.bio\")\n",
        "test_dataset  = prepare_dataset_from_bio(\"/content/abstracts07_06_bio_test_90_5_5.bio\")\n",
        "\n",
        "# 🔍 Vérification\n",
        "print(\"✅ Datasets créés :\")\n",
        "print(\"Exemple train_dataset :\")\n",
        "print(train_dataset[0])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xulRwcOFSwUP",
        "outputId": "15891c28-e954-4d09-b2bf-c18de34e9526"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Datasets créés :\n",
            "Exemple train_dataset :\n",
            "{'input_ids': [101, 122, 25128, 4386, 1306, 185, 7111, 1918, 2528, 1233, 17881, 1571, 179, 3488, 127, 12737, 1568, 21336, 9465, 1275, 7393, 1545, 179, 171, 1665, 1643, 17881, 1571, 12737, 1568, 21336, 3294, 3075, 5911, 2393, 1377, 1830, 1324, 1559, 2394, 3052, 26410, 13499, 3946, 2629, 16516, 6602, 15796, 3850, 172, 1548, 1643, 16236, 1394, 10645, 12104, 16042, 3773, 23220, 4993, 177, 122, 177, 1358, 193, 123, 195, 10436, 1403, 181, 124, 16358, 2118, 194, 125, 2351, 1869, 122, 2853, 1137, 1582, 15680, 4724, 188, 17204, 10390, 8281, 1234, 188, 2704, 11371, 1403, 3454, 2755, 1278, 5182, 188, 17204, 10390, 1539, 1559, 1477, 185, 1197, 5144, 1161, 1278, 1297, 2332, 8614, 175, 20257, 9513, 2755, 2598, 2815, 175, 14875, 14640, 8301, 10424, 1580, 185, 1197, 5144, 1161, 123, 1131, 19411, 10436, 2057, 13306, 3653, 1654, 13347, 1131, 19411, 10436, 8918, 4167, 21943, 4807, 1131, 19411, 10436, 4062, 18910, 10973, 185, 1197, 5144, 1161, 124, 2853, 1137, 1582, 15680, 4724, 188, 17204, 10390, 8281, 1234, 188, 2704, 11371, 1403, 3454, 2755, 1278, 5182, 188, 17204, 10390, 1539, 1559, 1477, 185, 1197, 5144, 1161, 4828, 4134, 16358, 2118, 10279, 16740, 175, 9379, 2050, 5048, 1358, 172, 1179, 125, 1278, 1297, 2332, 8614, 175, 20257, 9513, 2755, 2598, 2815, 175, 14875, 14640, 8301, 10424, 1580, 185, 1197, 5144, 1161, 4828, 4134, 173, 1197, 195, 10436, 1403, 11371, 1403, 3454, 5048, 1358, 172, 1179, 172, 1548, 1643, 16236, 1394, 18106, 22572, 5521, 12858, 5970, 3186, 16065, 1665, 3850, 3409, 1215, 7299, 4182, 1116, 16679, 1166, 7409, 19172, 6856, 16042, 5250, 23984, 15511, 5552, 2765, 185, 1204, 1665, 2686, 5199, 12104, 16042, 3773, 170, 2293, 16516, 6602, 15796, 5557, 1263, 1215, 7299, 3245, 8005, 10879, 2556, 14196, 14441, 8936, 1119, 8031, 12809, 11179, 1200, 185, 7777, 9012, 8974, 5426, 1193, 9619, 3469, 16516, 6602, 15796, 5557, 1169, 1145, 26410, 25342, 172, 1548, 1643, 16236, 1394, 10645, 170, 2293, 10311, 6978, 2606, 3655, 2025, 1276, 1256, 1822, 14759, 16516, 6602, 15796, 1169, 2773, 8115, 2603, 1769, 185, 1204, 1665, 1852, 12177, 172, 1548, 1643, 16236, 1394, 7401, 1606, 4321, 18882, 6063, 4592, 1353, 14730, 8234, 4884, 3626, 27850, 3926, 7861, 4592, 2393, 1377, 1830, 1324, 1559, 2747, 4010, 16516, 6602, 15796, 5565, 13251, 27466, 7836, 4869, 7160, 2393, 1377, 1830, 1324, 1559, 1260, 7136, 2116, 5958, 6986, 2765, 8115, 2603, 1852, 12177, 172, 1548, 1643, 16236, 1394, 7401, 1276, 16516, 6602, 15796, 3252, 1260, 7136, 3052, 2393, 1377, 1830, 1324, 1559, 14105, 16042, 17356, 172, 1548, 1643, 16236, 1394, 10645, 170, 2293, 2905, 2554, 5401, 2393, 1377, 1830, 1324, 1559, 2747, 4010, 16516, 6602, 15796, 5557, 2393, 1377, 1830, 1324, 1559, 27558, 1116, 3209, 3850, 4765, 26410, 13499, 2116, 172, 1548, 1643, 16236, 1394, 10645, 170, 2293, 11409, 17881, 1571, 1502, 1950, 15339, 1107, 1665, 9465, 1275, 7393, 1545, 179, 171, 1665, 1643, 17881, 1571, 12737, 1568, 21336, 9852, 2386, 27993, 1604, 12882, 23249, 4139, 2199, 4195, 11156, 6259, 2199, 5752, 14197, 1227, 6259, 2798, 4740, 2357, 6085, 1691, 2933, 1250, 2103, 2526, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 2, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 3, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 3, 3, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 3, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 3, -100, -100, -100, -100, -100, -100, -100, -100, 3, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 2, -100, -100, -100, 2, -100, -100, -100, -100, -100, -100, 2, -100, 2, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 2, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 2, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 2, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 2, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
        "import numpy as np\n",
        "from seqeval.metrics import classification_report, accuracy_score, f1_score\n",
        "\n",
        "# ✅ Charger le modèle pré-entraîné\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    \"dmis-lab/biobert-base-cased-v1.1\",\n",
        "    num_labels=len(label_list),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")\n",
        "\n",
        "# 📊 Métriques d’évaluation\n",
        "def compute_metrics(p):\n",
        "    preds = np.argmax(p.predictions, axis=2)\n",
        "    labels = p.label_ids\n",
        "\n",
        "    true_predictions = [\n",
        "        [id2label[p] for (p, l) in zip(pred, label) if l != -100]\n",
        "        for pred, label in zip(preds, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [id2label[l] for (p, l) in zip(pred, label) if l != -100]\n",
        "        for pred, label in zip(preds, labels)\n",
        "    ]\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(true_labels, true_predictions),\n",
        "        \"f1\": f1_score(true_labels, true_predictions),\n",
        "        \"report\": classification_report(true_labels, true_predictions, output_dict=False)\n",
        "    }\n",
        "\n",
        "# 🔧 Arguments d'entraînement\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./ner_biobert\",\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=4,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=50,\n",
        "    save_steps=500,\n",
        "    eval_steps=500,\n",
        "    save_total_limit=2,\n",
        ")\n",
        "\n",
        "# 🚀 Entraînement avec Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "d22G2TdZS3eZ",
        "outputId": "46ebfcbb-8114-419e-b23b-7d78cbd2a9e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-38-3145e7aac804>:51: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='144' max='144' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [144/144 01:58, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.558500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.124400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=144, training_loss=0.2566818479034636, metrics={'train_runtime': 119.0834, 'train_samples_per_second': 9.674, 'train_steps_per_second': 1.209, 'total_flos': 301022028103680.0, 'train_loss': 0.2566818479034636, 'epoch': 4.0})"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Évaluer le modèle sur le jeu de validation\n",
        "results = trainer.evaluate()\n",
        "\n",
        "# Affichage des métriques principales\n",
        "print(\"📊 Résultats de l'évaluation :\")\n",
        "print(f\"Accuracy : {results['eval_accuracy']:.4f}\")\n",
        "print(f\"F1-score : {results['eval_f1']:.4f}\")\n",
        "print(\"\\n📄 Rapport détaillé :\")\n",
        "print(results['eval_report'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "wvL5uSnLS7Q0",
        "outputId": "ce6ff25f-751e-4389-8a11-621c6b59f672"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2/2 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Résultats de l'évaluation :\n",
            "Accuracy : 1.0000\n",
            "F1-score : 1.0000\n",
            "\n",
            "📄 Rapport détaillé :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     DISEASE       1.00      1.00      1.00        49\n",
            "        GENE       1.00      1.00      1.00        38\n",
            "     PROTEIN       1.00      1.00      1.00         5\n",
            "     SYMPTOM       1.00      1.00      1.00         1\n",
            "\n",
            "   micro avg       1.00      1.00      1.00        93\n",
            "   macro avg       1.00      1.00      1.00        93\n",
            "weighted avg       1.00      1.00      1.00        93\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 📊 Évaluation sur le jeu de test\n",
        "test_results = trainer.evaluate(eval_dataset=test_dataset)\n",
        "\n",
        "# 📋 Affichage des métriques\n",
        "print(\"📊 Résultats sur le jeu de test :\")\n",
        "print(f\"Accuracy : {test_results['eval_accuracy']:.4f}\")\n",
        "print(f\"F1-score : {test_results['eval_f1']:.4f}\")\n",
        "print(\"\\n📄 Rapport détaillé :\")\n",
        "print(test_results['eval_report'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "rpdnUlhgS_p8",
        "outputId": "481ba435-72a5-4251-8b9d-6c582881ba91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2/2 00:10]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Résultats sur le jeu de test :\n",
            "Accuracy : 0.9417\n",
            "F1-score : 0.9417\n",
            "\n",
            "📄 Rapport détaillé :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     DISEASE       0.97      1.00      0.98        61\n",
            "        GENE       0.96      0.83      0.89        29\n",
            "     PROTEIN       0.80      0.92      0.86        13\n",
            "\n",
            "   micro avg       0.94      0.94      0.94       103\n",
            "   macro avg       0.91      0.92      0.91       103\n",
            "weighted avg       0.94      0.94      0.94       103\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "source_dir = \"/content\"\n",
        "target_dir = \"/content/drive/MyDrive/NLP_dernier_modification_09_06_90_5_5\"\n",
        "\n",
        "# Créer le dossier cible s’il n’existe pas\n",
        "os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "# Parcourir tous les fichiers/dossiers dans /content sauf /content/drive\n",
        "for item in os.listdir(source_dir):\n",
        "    src_path = os.path.join(source_dir, item)\n",
        "    dst_path = os.path.join(target_dir, item)\n",
        "\n",
        "    if item == \"drive\":\n",
        "        continue  # ⚠️ Ignorer le dossier Google Drive\n",
        "\n",
        "    try:\n",
        "        if os.path.isdir(src_path):\n",
        "            shutil.copytree(src_path, dst_path, dirs_exist_ok=True)\n",
        "        else:\n",
        "            shutil.copy2(src_path, dst_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Erreur en copiant {item} : {e}\")\n",
        "\n",
        "print(f\"✅ Tous les fichiers (sauf /drive) ont été copiés vers : {target_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z23Sv7FfTEvk",
        "outputId": "e3256f24-4261-49c3-a6ae-34994f787d3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Tous les fichiers (sauf /drive) ont été copiés vers : /content/drive/MyDrive/NLP_dernier_modification_09_06_90_5_5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "n6hYfS_7STrB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### _70_15_15"
      ],
      "metadata": {
        "id": "xt3KEv-IVndD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import ast\n",
        "\n",
        "# Download 'punkt' for word_tokenize (already done, but good practice to keep)\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Download the specific 'punkt_tab' resource mentioned in the error\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "\n",
        "# 📌 Fonction principale pour annotation BIO\n",
        "def annotate_bio(df, output_path):\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as fout:\n",
        "        for _, row in df.iterrows():\n",
        "            abstract = row['cleaned']  # ✅ colonne contenant le texte nettoyé\n",
        "\n",
        "            # Assurez-vous que la colonne 'cleaned' n'est pas vide ou None\n",
        "            if pd.isna(abstract) or abstract.strip() == \"\":\n",
        "                 continue # Ignore les lignes sans texte nettoyé\n",
        "\n",
        "            try:\n",
        "                # Utiliser un ensemble vide si la colonne n'existe pas\n",
        "                # ou si l'évaluation échoue\n",
        "                genes = set(ast.literal_eval(row.get('genes', '[]')))\n",
        "                proteins = set(ast.literal_eval(row.get('proteins', '[]')))\n",
        "                diseases = set(ast.literal_eval(row.get('diseases', '[]')))\n",
        "                symptoms = set(ast.literal_eval(row.get('symptoms', '[]')))\n",
        "            except Exception as e:\n",
        "                print(f\"Erreur parsing à la ligne {row.name} : {e}\")\n",
        "                continue\n",
        "\n",
        "            # Gérer les cas où abstract pourrait être None ou non-string\n",
        "            if not isinstance(abstract, str):\n",
        "                 print(f\"Ligne {row.name} a un type d'abstract inattendu: {type(abstract)}\")\n",
        "                 continue\n",
        "\n",
        "\n",
        "            tokens = word_tokenize(abstract)\n",
        "\n",
        "            for token in tokens:\n",
        "                tag = \"O\"\n",
        "                token_lower = token.lower()\n",
        "                token_upper = token.upper()\n",
        "\n",
        "                # Itérer sur les ensembles d'entités\n",
        "                if token_upper in genes:\n",
        "                    tag = \"B-GENE\"\n",
        "                elif token_lower in proteins:\n",
        "                    tag = \"B-PROTEIN\"\n",
        "                elif token_lower in diseases:\n",
        "                    tag = \"B-DISEASE\"\n",
        "                elif token_lower in symptoms:\n",
        "                    tag = \"B-SYMPTOM\"\n",
        "\n",
        "                fout.write(f\"{token} {tag}\\n\")\n",
        "            fout.write(\"\\n\")\n",
        "\n",
        "    print(f\"✅ Fichier BIO sauvegardé dans : {output_path}\")\n",
        "\n",
        "# 🔄 Chargement des fichiers\n",
        "train_df = pd.read_csv(\"/content/abstracts07_06_train_70_15_15.csv\")\n",
        "val_df   = pd.read_csv(\"/content/abstracts07_06_val_70_15_15.csv\")\n",
        "test_df  = pd.read_csv(\"/content/abstracts07_06_test_70_15_15.csv\")\n",
        "\n",
        "# 📝 Application\n",
        "annotate_bio(train_df, \"/content/abstracts07_06_bio_train_70_15_15.bio\")\n",
        "annotate_bio(val_df, \"/content/abstracts07_06_bio_val_70_15_15.bio\")\n",
        "annotate_bio(test_df, \"/content/abstracts07_06_bio_test_70_15_15.bio\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDSw6OSEYYpy",
        "outputId": "36a67b33-49be-4596-9c40-efb1acf00392"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fichier BIO sauvegardé dans : /content/abstracts07_06_bio_train_70_15_15.bio\n",
            "✅ Fichier BIO sauvegardé dans : /content/abstracts07_06_bio_val_70_15_15.bio\n",
            "✅ Fichier BIO sauvegardé dans : /content/abstracts07_06_bio_test_70_15_15.bio\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Elle ignore les tokens \"O\" dans les labels pendant l'entraînement.\n",
        "\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# 📌 Modèle utilisé (BioBERT)\n",
        "model_name = \"dmis-lab/biobert-base-cased-v1.1\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# 🏷️ Étiquettes\n",
        "label_list = ['O', 'B-GENE', 'B-PROTEIN', 'B-DISEASE', 'B-SYMPTOM']\n",
        "label2id = {label: i for i, label in enumerate(label_list)}\n",
        "id2label = {i: label for label, i in label2id.items()}\n",
        "\n",
        "\n",
        "# 📄 Lire un fichier BIO et l'organiser par phrase\n",
        "def read_bio_file(filepath):\n",
        "    sentences = []\n",
        "    labels = []\n",
        "    current_tokens = []\n",
        "    current_labels = []\n",
        "\n",
        "    with open(filepath, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            if line.strip() == '':\n",
        "                if current_tokens:\n",
        "                    sentences.append(current_tokens)\n",
        "                    labels.append(current_labels)\n",
        "                    current_tokens = []\n",
        "                    current_labels = []\n",
        "            else:\n",
        "                splits = line.strip().split()\n",
        "                if len(splits) == 2:\n",
        "                    token, tag = splits\n",
        "                    current_tokens.append(token)\n",
        "                    current_labels.append(tag)\n",
        "\n",
        "        # Ajouter la dernière phrase si non vide\n",
        "        if current_tokens:\n",
        "            sentences.append(current_tokens)\n",
        "            labels.append(current_labels)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "\n",
        "# ✂️ Tokenisation + alignement des labels avec gestion du max_length\n",
        "#    et exclusion des tokens \"O\" (ignorés avec -100)\n",
        "def tokenize_and_align(sentences, tags, tokenizer):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        sentences,\n",
        "        is_split_into_words=True,\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        padding=\"max_length\",\n",
        "        return_tensors=None\n",
        "    )\n",
        "\n",
        "    aligned_labels = []\n",
        "    for i, label in enumerate(tags):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            elif word_idx != previous_word_idx:\n",
        "                tag = label[word_idx]\n",
        "                label_ids.append(label2id[tag] if tag != \"O\" else -100)\n",
        "            else:\n",
        "                label_ids.append(-100)\n",
        "            previous_word_idx = word_idx\n",
        "\n",
        "        aligned_labels.append(label_ids)\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = aligned_labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "\n",
        "# 📁 Préparer un Dataset HuggingFace depuis un fichier BIO\n",
        "def prepare_dataset_from_bio(filepath):\n",
        "    sents, tags = read_bio_file(filepath)\n",
        "    tokenized = tokenize_and_align(sents, tags, tokenizer)\n",
        "    return Dataset.from_dict(tokenized)\n",
        "\n",
        "\n",
        "# ✅ Créer les datasets avec les bons fichiers\n",
        "train_dataset = prepare_dataset_from_bio(\"//content/abstracts07_06_bio_train_70_15_15.bio\")\n",
        "val_dataset   = prepare_dataset_from_bio(\"/content/abstracts07_06_bio_val_70_15_15.bio\")\n",
        "test_dataset  = prepare_dataset_from_bio(\"/content/abstracts07_06_bio_test_70_15_15.bio\")\n",
        "\n",
        "# 🔍 Vérification\n",
        "print(\"✅ Datasets créés :\")\n",
        "print(\"Exemple train_dataset :\")\n",
        "print(train_dataset[0])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4NTiOyGYh3k",
        "outputId": "727a8202-5d8f-43bd-90df-e9e183349207"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Datasets créés :\n",
            "Exemple train_dataset :\n",
            "{'input_ids': [101, 122, 195, 15564, 12491, 194, 1182, 193, 4175, 195, 1161, 195, 3031, 17881, 1571, 179, 3488, 1275, 8359, 1659, 12445, 11004, 9465, 1275, 3413, 16480, 3975, 1161, 179, 172, 1179, 14541, 18202, 26303, 17881, 11049, 23117, 1475, 3135, 1580, 1604, 1477, 3772, 6600, 2272, 18250, 3246, 1558, 16798, 3621, 25575, 1958, 1664, 1353, 2765, 13093, 4182, 4420, 1606, 1407, 175, 175, 1181, 1403, 11109, 172, 1204, 3342, 5144, 6420, 11108, 1907, 5144, 6420, 6654, 181, 1182, 192, 122, 181, 1182, 179, 1324, 123, 195, 6583, 179, 1665, 122, 20049, 2118, 193, 1403, 122, 192, 1358, 179, 122, 195, 17204, 181, 3361, 123, 11078, 2118, 176, 2087, 122, 2351, 1869, 122, 2853, 4272, 5182, 1704, 2704, 2638, 5184, 2663, 23220, 1179, 1979, 2704, 2657, 1278, 9468, 21440, 2118, 2755, 9468, 21440, 2118, 13075, 7629, 1477, 5144, 1161, 123, 2853, 2070, 6360, 1704, 2704, 2638, 5184, 2663, 23220, 1179, 1979, 2704, 2657, 1278, 9468, 21440, 2118, 2755, 9468, 21440, 2118, 13075, 7629, 1477, 5144, 1161, 7649, 8664, 9815, 6600, 2272, 18250, 3246, 188, 1605, 1558, 16798, 3621, 25575, 1958, 23639, 1162, 1664, 1353, 2765, 13093, 4182, 183, 1116, 1665, 1233, 1665, 4420, 1359, 1407, 2087, 23896, 2007, 10649, 1183, 1403, 7535, 13538, 1162, 185, 2155, 2875, 3484, 17744, 1106, 3702, 8944, 3254, 18505, 1106, 3702, 8944, 1407, 2087, 175, 1181, 1403, 11109, 172, 1204, 4069, 4420, 3507, 7542, 1193, 3659, 12645, 183, 1116, 1665, 1233, 1665, 1655, 1141, 1214, 2812, 18675, 1193, 4465, 9468, 21440, 2118, 23220, 1179, 1979, 2704, 179, 19762, 3113, 1857, 1260, 2093, 10615, 10351, 4420, 15819, 1407, 2087, 175, 1181, 1403, 11109, 172, 1204, 2229, 172, 1204, 2259, 2568, 4177, 4010, 3582, 6022, 189, 1830, 10841, 1775, 4718, 1821, 1183, 1403, 6919, 1161, 2533, 188, 1605, 6028, 12477, 8674, 2533, 6028, 12477, 8674, 3246, 171, 1918, 1884, 15789, 1616, 18593, 15355, 3884, 1884, 15789, 1616, 18593, 15355, 2794, 11019, 6063, 7140, 4420, 15965, 2452, 2915, 5884, 23639, 1162, 2259, 2568, 7300, 7898, 188, 1605, 171, 1918, 11019, 6063, 3402, 1160, 2114, 4420, 3233, 1822, 1344, 1821, 1183, 1403, 6919, 1161, 189, 1830, 10841, 1775, 2114, 2452, 3151, 1821, 1183, 1403, 6919, 1161, 189, 1830, 10841, 1775, 2452, 11019, 6063, 4420, 11019, 6063, 121, 5667, 1664, 11019, 1233, 6617, 11531, 1372, 11019, 6063, 121, 5667, 11019, 1233, 6617, 11531, 1372, 24181, 1643, 4371, 1143, 2852, 3622, 1215, 4928, 8115, 10642, 9366, 3997, 2774, 4071, 14133, 9455, 16016, 5408, 23639, 1162, 21014, 1884, 1775, 15122, 26302, 2235, 1982, 19774, 3187, 5320, 23639, 1162, 2686, 1703, 5706, 183, 1116, 1665, 1233, 1665, 4420, 1529, 4079, 5391, 128, 1429, 122, 1201, 1259, 5073, 3508, 5046, 121, 1492, 4420, 1492, 129, 23639, 1162, 1301, 4455, 5615, 4420, 5942, 123, 1664, 23639, 1162, 1372, 1821, 1183, 1403, 6919, 1161, 189, 1830, 10841, 1775, 1884, 15789, 1616, 18593, 15355, 3884, 11019, 6063, 23639, 1162, 1372, 20844, 2895, 1664, 23639, 1162, 1372, 2812, 1159, 182, 186, 1475, 186, 1495, 3746, 1627, 4650, 1808, 27574, 21014, 23639, 1162, 1344, 1821, 1183, 1403, 6919, 1161, 189, 1830, 10841, 1775, 1372, 2299, 1822, 1821, 1183, 1403, 6919, 1161, 189, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 3, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 3, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
        "import numpy as np\n",
        "from seqeval.metrics import classification_report, accuracy_score, f1_score\n",
        "\n",
        "# ✅ Charger le modèle pré-entraîné\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    \"dmis-lab/biobert-base-cased-v1.1\",\n",
        "    num_labels=len(label_list),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")\n",
        "\n",
        "# 📊 Métriques d’évaluation\n",
        "def compute_metrics(p):\n",
        "    preds = np.argmax(p.predictions, axis=2)\n",
        "    labels = p.label_ids\n",
        "\n",
        "    true_predictions = [\n",
        "        [id2label[p] for (p, l) in zip(pred, label) if l != -100]\n",
        "        for pred, label in zip(preds, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [id2label[l] for (p, l) in zip(pred, label) if l != -100]\n",
        "        for pred, label in zip(preds, labels)\n",
        "    ]\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(true_labels, true_predictions),\n",
        "        \"f1\": f1_score(true_labels, true_predictions),\n",
        "        \"report\": classification_report(true_labels, true_predictions, output_dict=False)\n",
        "    }\n",
        "\n",
        "# 🔧 Arguments d'entraînement\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./ner_biobert\",\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=4,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=50,\n",
        "    save_steps=500,\n",
        "    eval_steps=500,\n",
        "    save_total_limit=2,\n",
        ")\n",
        "\n",
        "# 🚀 Entraînement avec Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "bfbUk07xYnsH",
        "outputId": "7bd0df67-4079-4fa6-e5a0-5a399130cad1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-44-3145e7aac804>:51: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='112' max='112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [112/112 02:15, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.594200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.138300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=112, training_loss=0.3349013738334179, metrics={'train_runtime': 136.8084, 'train_samples_per_second': 6.549, 'train_steps_per_second': 0.819, 'total_flos': 234128244080640.0, 'train_loss': 0.3349013738334179, 'epoch': 4.0})"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Évaluer le modèle sur le jeu de validation\n",
        "results = trainer.evaluate()\n",
        "\n",
        "# Affichage des métriques principales\n",
        "print(\"📊 Résultats de l'évaluation :\")\n",
        "print(f\"Accuracy : {results['eval_accuracy']:.4f}\")\n",
        "print(f\"F1-score : {results['eval_f1']:.4f}\")\n",
        "print(\"\\n📄 Rapport détaillé :\")\n",
        "print(results['eval_report'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "LL25oxRfYrIh",
        "outputId": "1b78e2a3-eb75-4e26-d3cc-78c7965b7fae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6/6 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Résultats de l'évaluation :\n",
            "Accuracy : 0.9549\n",
            "F1-score : 0.9549\n",
            "\n",
            "📄 Rapport détaillé :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     DISEASE       0.99      0.98      0.98       162\n",
            "        GENE       0.89      0.97      0.93        64\n",
            "     PROTEIN       0.95      0.95      0.95       148\n",
            "     SYMPTOM       0.00      0.00      0.00         3\n",
            "\n",
            "   micro avg       0.95      0.95      0.95       377\n",
            "   macro avg       0.71      0.72      0.71       377\n",
            "weighted avg       0.95      0.95      0.95       377\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 📊 Évaluation sur le jeu de test\n",
        "test_results = trainer.evaluate(eval_dataset=test_dataset)\n",
        "\n",
        "# 📋 Affichage des métriques\n",
        "print(\"📊 Résultats sur le jeu de test :\")\n",
        "print(f\"Accuracy : {test_results['eval_accuracy']:.4f}\")\n",
        "print(f\"F1-score : {test_results['eval_f1']:.4f}\")\n",
        "print(\"\\n📄 Rapport détaillé :\")\n",
        "print(test_results['eval_report'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "2jDUXNcnYvaS",
        "outputId": "fba486ee-3706-4234-997d-316e30170f69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='12' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6/6 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Résultats sur le jeu de test :\n",
            "Accuracy : 0.9563\n",
            "F1-score : 0.9563\n",
            "\n",
            "📄 Rapport détaillé :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     DISEASE       0.98      1.00      0.99       144\n",
            "        GENE       0.90      0.94      0.92        78\n",
            "     PROTEIN       0.97      0.91      0.94        97\n",
            "     SYMPTOM       1.00      1.00      1.00         1\n",
            "\n",
            "   micro avg       0.96      0.96      0.96       320\n",
            "   macro avg       0.96      0.96      0.96       320\n",
            "weighted avg       0.96      0.96      0.96       320\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "source_dir = \"/content\"\n",
        "target_dir = \"/content/drive/MyDrive/NLP_dernier_modification_09_06_70_15_15\"\n",
        "\n",
        "# Créer le dossier cible s’il n’existe pas\n",
        "os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "# Parcourir tous les fichiers/dossiers dans /content sauf /content/drive\n",
        "for item in os.listdir(source_dir):\n",
        "    src_path = os.path.join(source_dir, item)\n",
        "    dst_path = os.path.join(target_dir, item)\n",
        "\n",
        "    if item == \"drive\":\n",
        "        continue  # ⚠️ Ignorer le dossier Google Drive\n",
        "\n",
        "    try:\n",
        "        if os.path.isdir(src_path):\n",
        "            shutil.copytree(src_path, dst_path, dirs_exist_ok=True)\n",
        "        else:\n",
        "            shutil.copy2(src_path, dst_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Erreur en copiant {item} : {e}\")\n",
        "\n",
        "print(f\"✅ Tous les fichiers (sauf /drive) ont été copiés vers : {target_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUqkiWa8ZdPA",
        "outputId": "5b7b14e6-ee45-4934-f080-5b484eb846b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Tous les fichiers (sauf /drive) ont été copiés vers : /content/drive/MyDrive/NLP_dernier_modification_09_06_70_15_15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "_______________________________________________________________"
      ],
      "metadata": {
        "id": "IZhjkyR_YY78"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### _60_20_20"
      ],
      "metadata": {
        "id": "h4Ui8VCoVvgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import ast\n",
        "\n",
        "# Download 'punkt' for word_tokenize (already done, but good practice to keep)\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Download the specific 'punkt_tab' resource mentioned in the error\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "\n",
        "# 📌 Fonction principale pour annotation BIO\n",
        "def annotate_bio(df, output_path):\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as fout:\n",
        "        for _, row in df.iterrows():\n",
        "            abstract = row['cleaned']  # ✅ colonne contenant le texte nettoyé\n",
        "\n",
        "            # Assurez-vous que la colonne 'cleaned' n'est pas vide ou None\n",
        "            if pd.isna(abstract) or abstract.strip() == \"\":\n",
        "                 continue # Ignore les lignes sans texte nettoyé\n",
        "\n",
        "            try:\n",
        "                # Utiliser un ensemble vide si la colonne n'existe pas\n",
        "                # ou si l'évaluation échoue\n",
        "                genes = set(ast.literal_eval(row.get('genes', '[]')))\n",
        "                proteins = set(ast.literal_eval(row.get('proteins', '[]')))\n",
        "                diseases = set(ast.literal_eval(row.get('diseases', '[]')))\n",
        "                symptoms = set(ast.literal_eval(row.get('symptoms', '[]')))\n",
        "            except Exception as e:\n",
        "                print(f\"Erreur parsing à la ligne {row.name} : {e}\")\n",
        "                continue\n",
        "\n",
        "            # Gérer les cas où abstract pourrait être None ou non-string\n",
        "            if not isinstance(abstract, str):\n",
        "                 print(f\"Ligne {row.name} a un type d'abstract inattendu: {type(abstract)}\")\n",
        "                 continue\n",
        "\n",
        "\n",
        "            tokens = word_tokenize(abstract)\n",
        "\n",
        "            for token in tokens:\n",
        "                tag = \"O\"\n",
        "                token_lower = token.lower()\n",
        "                token_upper = token.upper()\n",
        "\n",
        "                # Itérer sur les ensembles d'entités\n",
        "                if token_upper in genes:\n",
        "                    tag = \"B-GENE\"\n",
        "                elif token_lower in proteins:\n",
        "                    tag = \"B-PROTEIN\"\n",
        "                elif token_lower in diseases:\n",
        "                    tag = \"B-DISEASE\"\n",
        "                elif token_lower in symptoms:\n",
        "                    tag = \"B-SYMPTOM\"\n",
        "\n",
        "                fout.write(f\"{token} {tag}\\n\")\n",
        "            fout.write(\"\\n\")\n",
        "\n",
        "    print(f\"✅ Fichier BIO sauvegardé dans : {output_path}\")\n",
        "\n",
        "# 🔄 Chargement des fichiers\n",
        "train_df = pd.read_csv(\"/content/abstracts07_06_train_60_20_20.csv\")\n",
        "val_df   = pd.read_csv(\"/content/abstracts07_06_val_60_20_20.csv\")\n",
        "test_df  = pd.read_csv(\"/content/abstracts07_06_test_60_20_20.csv\")\n",
        "\n",
        "# 📝 Application\n",
        "annotate_bio(train_df, \"/content/abstracts07_06_bio_train_60_20_20.bio\")\n",
        "annotate_bio(val_df, \"/content/abstracts07_06_bio_val_60_20_20.bio\")\n",
        "annotate_bio(test_df, \"/content/abstracts07_06_bio_test_60_20_20.bio\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utpG__34behO",
        "outputId": "9fb3f2f9-f990-4850-b92e-37170e6b6687"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fichier BIO sauvegardé dans : /content/abstracts07_06_bio_train_60_20_20.bio\n",
            "✅ Fichier BIO sauvegardé dans : /content/abstracts07_06_bio_val_60_20_20.bio\n",
            "✅ Fichier BIO sauvegardé dans : /content/abstracts07_06_bio_test_60_20_20.bio\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Elle ignore les tokens \"O\" dans les labels pendant l'entraînement.\n",
        "\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# 📌 Modèle utilisé (BioBERT)\n",
        "model_name = \"dmis-lab/biobert-base-cased-v1.1\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# 🏷️ Étiquettes\n",
        "label_list = ['O', 'B-GENE', 'B-PROTEIN', 'B-DISEASE', 'B-SYMPTOM']\n",
        "label2id = {label: i for i, label in enumerate(label_list)}\n",
        "id2label = {i: label for label, i in label2id.items()}\n",
        "\n",
        "\n",
        "# 📄 Lire un fichier BIO et l'organiser par phrase\n",
        "def read_bio_file(filepath):\n",
        "    sentences = []\n",
        "    labels = []\n",
        "    current_tokens = []\n",
        "    current_labels = []\n",
        "\n",
        "    with open(filepath, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            if line.strip() == '':\n",
        "                if current_tokens:\n",
        "                    sentences.append(current_tokens)\n",
        "                    labels.append(current_labels)\n",
        "                    current_tokens = []\n",
        "                    current_labels = []\n",
        "            else:\n",
        "                splits = line.strip().split()\n",
        "                if len(splits) == 2:\n",
        "                    token, tag = splits\n",
        "                    current_tokens.append(token)\n",
        "                    current_labels.append(tag)\n",
        "\n",
        "        # Ajouter la dernière phrase si non vide\n",
        "        if current_tokens:\n",
        "            sentences.append(current_tokens)\n",
        "            labels.append(current_labels)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "\n",
        "# ✂️ Tokenisation + alignement des labels avec gestion du max_length\n",
        "#    et exclusion des tokens \"O\" (ignorés avec -100)\n",
        "def tokenize_and_align(sentences, tags, tokenizer):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        sentences,\n",
        "        is_split_into_words=True,\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        padding=\"max_length\",\n",
        "        return_tensors=None\n",
        "    )\n",
        "\n",
        "    aligned_labels = []\n",
        "    for i, label in enumerate(tags):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            elif word_idx != previous_word_idx:\n",
        "                tag = label[word_idx]\n",
        "                label_ids.append(label2id[tag] if tag != \"O\" else -100)\n",
        "            else:\n",
        "                label_ids.append(-100)\n",
        "            previous_word_idx = word_idx\n",
        "\n",
        "        aligned_labels.append(label_ids)\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = aligned_labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "\n",
        "# 📁 Préparer un Dataset HuggingFace depuis un fichier BIO\n",
        "def prepare_dataset_from_bio(filepath):\n",
        "    sents, tags = read_bio_file(filepath)\n",
        "    tokenized = tokenize_and_align(sents, tags, tokenizer)\n",
        "    return Dataset.from_dict(tokenized)\n",
        "\n",
        "\n",
        "# ✅ Créer les datasets avec les bons fichiers\n",
        "train_dataset = prepare_dataset_from_bio(\"/content/abstracts07_06_bio_train_60_20_20.bio\")\n",
        "val_dataset   = prepare_dataset_from_bio(\"/content/abstracts07_06_bio_val_60_20_20.bio\")\n",
        "test_dataset  = prepare_dataset_from_bio(\"/content/abstracts07_06_bio_test_60_20_20.bio\")\n",
        "\n",
        "# 🔍 Vérification\n",
        "print(\"✅ Datasets créés :\")\n",
        "print(\"Exemple train_dataset :\")\n",
        "print(train_dataset[0])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RN5pSoUWbt0E",
        "outputId": "0b11ef95-a549-4334-f06b-5153a8bd9920"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Datasets créés :\n",
            "Exemple train_dataset :\n",
            "{'input_ids': [101, 122, 188, 6617, 1231, 1643, 17881, 1571, 179, 3488, 127, 1405, 122, 1816, 1571, 9465, 1275, 9550, 1604, 188, 25892, 1571, 1580, 1604, 5507, 1571, 5347, 1580, 1571, 1545, 194, 8362, 17800, 1158, 3234, 9468, 2728, 1403, 1494, 1200, 9077, 1346, 10322, 9712, 1830, 26503, 23510, 1606, 12630, 4035, 25444, 2443, 1107, 16792, 185, 12937, 1161, 3262, 171, 1320, 13252, 2050, 175, 122, 176, 5709, 11071, 1320, 184, 123, 22245, 7291, 190, 124, 11580, 3740, 172, 125, 126, 22572, 10961, 16631, 172, 127, 1260, 5579, 1200, 194, 126, 1301, 19411, 1162, 173, 125, 3840, 27006, 176, 125, 2351, 1869, 122, 2587, 10093, 22572, 3484, 12809, 17288, 8362, 25105, 3150, 181, 13292, 1874, 1260, 9304, 26731, 12132, 23449, 1830, 8359, 1568, 9304, 13356, 5999, 1129, 1233, 5389, 1818, 175, 1643, 12937, 2225, 23449, 1830, 123, 8362, 11083, 181, 15136, 172, 1179, 1733, 4035, 1116, 1260, 181, 15136, 22233, 1200, 1306, 15276, 1197, 1571, 22737, 1580, 5682, 1306, 1665, 190, 11964, 10424, 5691, 22997, 1527, 181, 15136, 175, 10555, 124, 172, 1179, 1733, 1107, 3464, 178, 10294, 1233, 8362, 25105, 3150, 1260, 25338, 10582, 2042, 175, 22120, 7629, 9468, 7232, 175, 10555, 125, 2587, 10093, 22572, 3484, 12809, 17288, 8362, 25105, 3150, 181, 13292, 1874, 1260, 9304, 26731, 12132, 23449, 1830, 8359, 1568, 9304, 13356, 5999, 1129, 1233, 5389, 1818, 126, 1664, 7378, 2952, 8117, 2587, 8362, 25105, 3150, 181, 13292, 1874, 1260, 9304, 26731, 12132, 23449, 1830, 8359, 1568, 9304, 13356, 5999, 1129, 1233, 5389, 1818, 127, 172, 1179, 1733, 22233, 1200, 1306, 176, 4359, 8918, 8362, 25105, 3150, 172, 2879, 7578, 12686, 4121, 8376, 172, 2879, 7578, 175, 1200, 13141, 175, 10555, 3073, 4060, 1643, 9180, 1891, 12477, 27568, 1811, 9712, 1830, 26503, 188, 2430, 7147, 5668, 2765, 2765, 2838, 1119, 25710, 27054, 1785, 1723, 4344, 21293, 1880, 19687, 14911, 5047, 2765, 3367, 178, 1665, 1306, 3652, 174, 8508, 27184, 174, 8508, 2838, 9468, 2728, 1403, 2501, 15416, 5318, 174, 8508, 7012, 3238, 6664, 21439, 2227, 2838, 5320, 2320, 6183, 1936, 9468, 2728, 1403, 1494, 1200, 9077, 17689, 5565, 2838, 15661, 26468, 1421, 1159, 23245, 1423, 2765, 14715, 13590, 18882, 1665, 2233, 27948, 1606, 12630, 4035, 25444, 25220, 4929, 2765, 2765, 1119, 25710, 27054, 1785, 4035, 25444, 9468, 2728, 1403, 8609, 4709, 4283, 18107, 4844, 1479, 2765, 3324, 2765, 2016, 8080, 2501, 1648, 174, 8508, 14911, 12890, 27182, 4035, 25444, 21138, 1626, 9077, 1887, 1421, 2233, 27948, 3626, 1210, 9077, 185, 25534, 1306, 1475, 1177, 1775, 1477, 177, 1179, 2087, 1527, 1161, 2133, 15661, 26468, 2838, 6692, 15700, 9468, 2728, 1403, 1982, 5565, 12638, 2443, 1107, 16792, 1606, 3621, 16931, 1306, 9932, 23244, 18107, 14189, 15416, 1348, 24329, 2686, 3090, 1210, 9077, 8245, 1231, 6617, 1643, 2180, 7867, 14915, 9468, 2728, 1403, 2724, 2765, 2016, 12638, 17853, 21293, 1116, 7012, 12806, 6134, 1884, 2838, 2231, 10034, 3622, 1423, 2765, 14715, 13590, 18882, 1665, 2233, 8362, 17800, 1116, 2620, 1648, 185, 25534, 1306, 1475, 1177, 1775, 1477, 177, 1179, 2087, 1527, 1161, 2501, 9077, 21439, 21739, 1193, 4448, 9468, 2728, 1403, 19687, 178, 1665, 1306, 23510, 17881, 1571, 2351, 188, 9465, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 1, -100, -100, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 1, -100, -100, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
        "import numpy as np\n",
        "from seqeval.metrics import classification_report, accuracy_score, f1_score\n",
        "\n",
        "# ✅ Charger le modèle pré-entraîné\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    \"dmis-lab/biobert-base-cased-v1.1\",\n",
        "    num_labels=len(label_list),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")\n",
        "\n",
        "# 📊 Métriques d’évaluation\n",
        "def compute_metrics(p):\n",
        "    preds = np.argmax(p.predictions, axis=2)\n",
        "    labels = p.label_ids\n",
        "\n",
        "    true_predictions = [\n",
        "        [id2label[p] for (p, l) in zip(pred, label) if l != -100]\n",
        "        for pred, label in zip(preds, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [id2label[l] for (p, l) in zip(pred, label) if l != -100]\n",
        "        for pred, label in zip(preds, labels)\n",
        "    ]\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(true_labels, true_predictions),\n",
        "        \"f1\": f1_score(true_labels, true_predictions),\n",
        "        \"report\": classification_report(true_labels, true_predictions, output_dict=False)\n",
        "    }\n",
        "\n",
        "# 🔧 Arguments d'entraînement\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./ner_biobert\",\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=4,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=50,\n",
        "    save_steps=500,\n",
        "    eval_steps=500,\n",
        "    save_total_limit=2,\n",
        ")\n",
        "\n",
        "# 🚀 Entraînement avec Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "extZMUtQbzEx",
        "outputId": "6c6d4181-bc32-495d-c266-e35766aa9bdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-63-3145e7aac804>:51: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='96' max='96' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [96/96 01:21, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.550300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=96, training_loss=0.3442710340023041, metrics={'train_runtime': 82.6827, 'train_samples_per_second': 9.289, 'train_steps_per_second': 1.161, 'total_flos': 200681352069120.0, 'train_loss': 0.3442710340023041, 'epoch': 4.0})"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Évaluer le modèle sur le jeu de validation\n",
        "results = trainer.evaluate()\n",
        "\n",
        "# Affichage des métriques principales\n",
        "print(\"📊 Résultats de l'évaluation :\")\n",
        "print(f\"Accuracy : {results['eval_accuracy']:.4f}\")\n",
        "print(f\"F1-score : {results['eval_f1']:.4f}\")\n",
        "print(\"\\n📄 Rapport détaillé :\")\n",
        "print(results['eval_report'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "Ncx9EdPmb_ky",
        "outputId": "a5f39e57-c844-4c9d-e197-b26f74ea4d68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [8/8 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Résultats de l'évaluation :\n",
            "Accuracy : 0.9110\n",
            "F1-score : 0.9110\n",
            "\n",
            "📄 Rapport détaillé :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     DISEASE       0.94      0.98      0.96       244\n",
            "        GENE       0.80      0.97      0.88       113\n",
            "     PROTEIN       0.95      0.82      0.88       210\n",
            "     SYMPTOM       0.00      0.00      0.00         6\n",
            "\n",
            "   micro avg       0.91      0.91      0.91       573\n",
            "   macro avg       0.67      0.69      0.68       573\n",
            "weighted avg       0.91      0.91      0.91       573\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 📊 Évaluation sur le jeu de test\n",
        "test_results = trainer.evaluate(eval_dataset=test_dataset)\n",
        "\n",
        "# 📋 Affichage des métriques\n",
        "print(\"📊 Résultats sur le jeu de test :\")\n",
        "print(f\"Accuracy : {test_results['eval_accuracy']:.4f}\")\n",
        "print(f\"F1-score : {test_results['eval_f1']:.4f}\")\n",
        "print(\"\\n📄 Rapport détaillé :\")\n",
        "print(test_results['eval_report'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "V2tdezcncIG3",
        "outputId": "d3b434f7-1dfc-4d04-c888-049f96cc4ab3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [8/8 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Résultats sur le jeu de test :\n",
            "Accuracy : 0.9710\n",
            "F1-score : 0.9710\n",
            "\n",
            "📄 Rapport détaillé :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     DISEASE       0.97      1.00      0.98       200\n",
            "        GENE       0.97      0.93      0.95        75\n",
            "     PROTEIN       0.98      0.94      0.96       104\n",
            "\n",
            "   micro avg       0.97      0.97      0.97       379\n",
            "   macro avg       0.97      0.96      0.97       379\n",
            "weighted avg       0.97      0.97      0.97       379\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "source_dir = \"/content\"\n",
        "target_dir = \"/content/drive/MyDrive/NLP_dernier_modification_09_06_60_20_20\"\n",
        "\n",
        "# Créer le dossier cible s’il n’existe pas\n",
        "os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "# Parcourir tous les fichiers/dossiers dans /content sauf /content/drive\n",
        "for item in os.listdir(source_dir):\n",
        "    src_path = os.path.join(source_dir, item)\n",
        "    dst_path = os.path.join(target_dir, item)\n",
        "\n",
        "    if item == \"drive\":\n",
        "        continue  # ⚠️ Ignorer le dossier Google Drive\n",
        "\n",
        "    try:\n",
        "        if os.path.isdir(src_path):\n",
        "            shutil.copytree(src_path, dst_path, dirs_exist_ok=True)\n",
        "        else:\n",
        "            shutil.copy2(src_path, dst_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Erreur en copiant {item} : {e}\")\n",
        "\n",
        "print(f\"✅ Tous les fichiers (sauf /drive) ont été copiés vers : {target_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9hfVRPhcIhL",
        "outputId": "bc246022-bde9-43b7-a15f-7afc09d67322"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Tous les fichiers (sauf /drive) ont été copiés vers : /content/drive/MyDrive/NLP_dernier_modification_09_06_60_20_20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "_____________________________________________________________________"
      ],
      "metadata": {
        "id": "kj0W8Poubex3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### _75_12.5_12.5"
      ],
      "metadata": {
        "id": "XgfCI1o4V19g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import ast\n",
        "\n",
        "# Download 'punkt' for word_tokenize (already done, but good practice to keep)\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Download the specific 'punkt_tab' resource mentioned in the error\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "\n",
        "# 📌 Fonction principale pour annotation BIO\n",
        "def annotate_bio(df, output_path):\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as fout:\n",
        "        for _, row in df.iterrows():\n",
        "            abstract = row['cleaned']  # ✅ colonne contenant le texte nettoyé\n",
        "\n",
        "            # Assurez-vous que la colonne 'cleaned' n'est pas vide ou None\n",
        "            if pd.isna(abstract) or abstract.strip() == \"\":\n",
        "                 continue # Ignore les lignes sans texte nettoyé\n",
        "\n",
        "            try:\n",
        "                # Utiliser un ensemble vide si la colonne n'existe pas\n",
        "                # ou si l'évaluation échoue\n",
        "                genes = set(ast.literal_eval(row.get('genes', '[]')))\n",
        "                proteins = set(ast.literal_eval(row.get('proteins', '[]')))\n",
        "                diseases = set(ast.literal_eval(row.get('diseases', '[]')))\n",
        "                symptoms = set(ast.literal_eval(row.get('symptoms', '[]')))\n",
        "            except Exception as e:\n",
        "                print(f\"Erreur parsing à la ligne {row.name} : {e}\")\n",
        "                continue\n",
        "\n",
        "            # Gérer les cas où abstract pourrait être None ou non-string\n",
        "            if not isinstance(abstract, str):\n",
        "                 print(f\"Ligne {row.name} a un type d'abstract inattendu: {type(abstract)}\")\n",
        "                 continue\n",
        "\n",
        "\n",
        "            tokens = word_tokenize(abstract)\n",
        "\n",
        "            for token in tokens:\n",
        "                tag = \"O\"\n",
        "                token_lower = token.lower()\n",
        "                token_upper = token.upper()\n",
        "\n",
        "                # Itérer sur les ensembles d'entités\n",
        "                if token_upper in genes:\n",
        "                    tag = \"B-GENE\"\n",
        "                elif token_lower in proteins:\n",
        "                    tag = \"B-PROTEIN\"\n",
        "                elif token_lower in diseases:\n",
        "                    tag = \"B-DISEASE\"\n",
        "                elif token_lower in symptoms:\n",
        "                    tag = \"B-SYMPTOM\"\n",
        "\n",
        "                fout.write(f\"{token} {tag}\\n\")\n",
        "            fout.write(\"\\n\")\n",
        "\n",
        "    print(f\"✅ Fichier BIO sauvegardé dans : {output_path}\")\n",
        "\n",
        "# 🔄 Chargement des fichiers\n",
        "train_df = pd.read_csv(\"/content/abstracts07_06_train_75_12.5_12.5.csv\")\n",
        "val_df   = pd.read_csv(\"/content/abstracts07_06_val_75_12.5_12.5.csv\")\n",
        "test_df  = pd.read_csv(\"/content/abstracts07_06_test_75_12.5_12.5.csv\")\n",
        "\n",
        "# 📝 Application\n",
        "annotate_bio(train_df, \"/content/abstracts07_06_bio_train_75_12.5_12.5.bio\")\n",
        "annotate_bio(val_df, \"/content/abstracts07_06_bio_val_75_12.5_12.5.bio\")\n",
        "annotate_bio(test_df, \"/content/abstracts07_06_bio_test_75_12.5_12.5.bio\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ohuMT5qeQU7",
        "outputId": "fc339a19-6137-4c70-f6c8-5887debbbd08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fichier BIO sauvegardé dans : /content/abstracts07_06_bio_train_75_12.5_12.5.bio\n",
            "✅ Fichier BIO sauvegardé dans : /content/abstracts07_06_bio_val_75_12.5_12.5.bio\n",
            "✅ Fichier BIO sauvegardé dans : /content/abstracts07_06_bio_test_75_12.5_12.5.bio\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Elle ignore les tokens \"O\" dans les labels pendant l'entraînement.\n",
        "\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# 📌 Modèle utilisé (BioBERT)\n",
        "model_name = \"dmis-lab/biobert-base-cased-v1.1\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# 🏷️ Étiquettes\n",
        "label_list = ['O', 'B-GENE', 'B-PROTEIN', 'B-DISEASE', 'B-SYMPTOM']\n",
        "label2id = {label: i for i, label in enumerate(label_list)}\n",
        "id2label = {i: label for label, i in label2id.items()}\n",
        "\n",
        "\n",
        "# 📄 Lire un fichier BIO et l'organiser par phrase\n",
        "def read_bio_file(filepath):\n",
        "    sentences = []\n",
        "    labels = []\n",
        "    current_tokens = []\n",
        "    current_labels = []\n",
        "\n",
        "    with open(filepath, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            if line.strip() == '':\n",
        "                if current_tokens:\n",
        "                    sentences.append(current_tokens)\n",
        "                    labels.append(current_labels)\n",
        "                    current_tokens = []\n",
        "                    current_labels = []\n",
        "            else:\n",
        "                splits = line.strip().split()\n",
        "                if len(splits) == 2:\n",
        "                    token, tag = splits\n",
        "                    current_tokens.append(token)\n",
        "                    current_labels.append(tag)\n",
        "\n",
        "        # Ajouter la dernière phrase si non vide\n",
        "        if current_tokens:\n",
        "            sentences.append(current_tokens)\n",
        "            labels.append(current_labels)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "\n",
        "# ✂️ Tokenisation + alignement des labels avec gestion du max_length\n",
        "#    et exclusion des tokens \"O\" (ignorés avec -100)\n",
        "def tokenize_and_align(sentences, tags, tokenizer):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        sentences,\n",
        "        is_split_into_words=True,\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        padding=\"max_length\",\n",
        "        return_tensors=None\n",
        "    )\n",
        "\n",
        "    aligned_labels = []\n",
        "    for i, label in enumerate(tags):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            elif word_idx != previous_word_idx:\n",
        "                tag = label[word_idx]\n",
        "                label_ids.append(label2id[tag] if tag != \"O\" else -100)\n",
        "            else:\n",
        "                label_ids.append(-100)\n",
        "            previous_word_idx = word_idx\n",
        "\n",
        "        aligned_labels.append(label_ids)\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = aligned_labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "\n",
        "# 📁 Préparer un Dataset HuggingFace depuis un fichier BIO\n",
        "def prepare_dataset_from_bio(filepath):\n",
        "    sents, tags = read_bio_file(filepath)\n",
        "    tokenized = tokenize_and_align(sents, tags, tokenizer)\n",
        "    return Dataset.from_dict(tokenized)\n",
        "\n",
        "\n",
        "# ✅ Créer les datasets avec les bons fichiers\n",
        "train_dataset = prepare_dataset_from_bio(\"//content/abstracts07_06_bio_train_75_12.5_12.5.bio\")\n",
        "val_dataset   = prepare_dataset_from_bio(\"/content/abstracts07_06_bio_val_75_12.5_12.5.bio\")\n",
        "test_dataset  = prepare_dataset_from_bio(\"/content/abstracts07_06_bio_test_75_12.5_12.5.bio\")\n",
        "\n",
        "# 🔍 Vérification\n",
        "print(\"✅ Datasets créés :\")\n",
        "print(\"Exemple train_dataset :\")\n",
        "print(train_dataset[0])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Pj6lWuVeYGe",
        "outputId": "258d8752-a6af-4339-e6d2-baee811497a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Datasets créés :\n",
            "Exemple train_dataset :\n",
            "{'input_ids': [101, 122, 1619, 1920, 4182, 17881, 1571, 179, 3488, 130, 3081, 128, 3731, 1604, 9465, 1275, 1620, 1559, 188, 7629, 1571, 10973, 5507, 1571, 4925, 1545, 14541, 127, 1679, 2660, 3365, 5838, 6730, 2112, 13035, 14471, 4420, 15819, 1113, 2528, 13791, 1596, 6059, 12818, 3189, 27154, 3622, 178, 15197, 13292, 1766, 172, 122, 1195, 22654, 12210, 1200, 183, 1197, 123, 1126, 2571, 3309, 188, 1116, 123, 2351, 1869, 122, 2417, 190, 13166, 8032, 1596, 1113, 12241, 2853, 190, 13166, 15741, 2755, 16946, 1465, 22572, 1813, 7841, 3052, 2138, 191, 1161, 1366, 1161, 172, 1182, 1571, 1181, 190, 2497, 13836, 6066, 1324, 8916, 123, 2853, 15190, 18766, 4807, 2755, 16946, 1465, 22572, 1813, 7841, 3052, 2138, 191, 1161, 1366, 1161, 3007, 17459, 3209, 3772, 1679, 2660, 3365, 5838, 6730, 8115, 2112, 13035, 14471, 1113, 2528, 13791, 1596, 4420, 15819, 13467, 1231, 25461, 4069, 12818, 3189, 7091, 2200, 4013, 7356, 23972, 1158, 1679, 2660, 3365, 5838, 6730, 1113, 2528, 13791, 1596, 4420, 15819, 13467, 1231, 25461, 1502, 1539, 17881, 1527, 1982, 9712, 14017, 11030, 4611, 5127, 2598, 1884, 1732, 18194, 3340, 8703, 13950, 2199, 1529, 1231, 10182, 21629, 1714, 8115, 3653, 1714, 8115, 4182, 2747, 8115, 2905, 8115, 2112, 13035, 14471, 2686, 2908, 1545, 4237, 3626, 126, 1899, 10838, 9173, 4311, 14166, 1113, 2528, 13791, 1596, 4420, 4172, 26600, 183, 123, 1119, 4163, 2430, 15197, 18665, 183, 122, 3245, 8005, 1279, 4184, 19911, 1348, 183, 122, 2942, 10294, 6163, 12814, 3377, 183, 122, 14166, 4420, 14747, 7091, 2200, 1679, 2660, 3365, 5838, 6730, 9108, 1679, 2660, 3365, 5838, 6730, 8318, 3073, 13035, 1193, 183, 125, 16859, 9355, 123, 2277, 183, 122, 124, 1808, 183, 122, 16859, 1822, 183, 122, 1344, 183, 122, 7657, 3322, 6730, 6716, 2316, 1529, 3179, 183, 126, 12951, 183, 125, 179, 8032, 3375, 183, 123, 1719, 2041, 4612, 20121, 1348, 15604, 21155, 22354, 12562, 1619, 2527, 1679, 2660, 3365, 5838, 6730, 4725, 1107, 28092, 3621, 18472, 1279, 8508, 11412, 1183, 12691, 1679, 2660, 3365, 5838, 6730, 4725, 3653, 1714, 8115, 1141, 2025, 2112, 13035, 14471, 11271, 1679, 2660, 3365, 5838, 6730, 1654, 2114, 6593, 7815, 2527, 1329, 1679, 2660, 3365, 5838, 6730, 9927, 2952, 12691, 1437, 2418, 2629, 2112, 13035, 14471, 8115, 2425, 1322, 7587, 1141, 1529, 2527, 2076, 6730, 6716, 1179, 9177, 3409, 9505, 2609, 6876, 2060, 13426, 2960, 6029, 1785, 1679, 2660, 3365, 5838, 6730, 6716, 2316, 1444, 2174, 7356, 5605, 4959, 2629, 6730, 1263, 1858, 1113, 2528, 13791, 1596, 1322, 21521, 17881, 1571, 2351, 188, 9465, 1275, 1620, 1559, 188, 7629, 1571, 10973, 5507, 1571, 4925, 1545, 14541, 127, 9852, 2386, 27993, 1604, 19203, 1604, 1580, 7448, 1174, 1143, 28054, 2042, 4139, 2199, 4195, 11156, 1116, 4139, 2199, 5752, 14197, 6259, 4740, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [-100, -100, -100, -100, 3, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 3, -100, -100, 3, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 3, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
        "import numpy as np\n",
        "from seqeval.metrics import classification_report, accuracy_score, f1_score\n",
        "\n",
        "# ✅ Charger le modèle pré-entraîné\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    \"dmis-lab/biobert-base-cased-v1.1\",\n",
        "    num_labels=len(label_list),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")\n",
        "\n",
        "# 📊 Métriques d’évaluation\n",
        "def compute_metrics(p):\n",
        "    preds = np.argmax(p.predictions, axis=2)\n",
        "    labels = p.label_ids\n",
        "\n",
        "    true_predictions = [\n",
        "        [id2label[p] for (p, l) in zip(pred, label) if l != -100]\n",
        "        for pred, label in zip(preds, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [id2label[l] for (p, l) in zip(pred, label) if l != -100]\n",
        "        for pred, label in zip(preds, labels)\n",
        "    ]\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(true_labels, true_predictions),\n",
        "        \"f1\": f1_score(true_labels, true_predictions),\n",
        "        \"report\": classification_report(true_labels, true_predictions, output_dict=False)\n",
        "    }\n",
        "\n",
        "# 🔧 Arguments d'entraînement\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./ner_biobert\",\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=4,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=50,\n",
        "    save_steps=500,\n",
        "    eval_steps=500,\n",
        "    save_total_limit=2,\n",
        ")\n",
        "\n",
        "# 🚀 Entraînement avec Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "eYs0pkoHefOx",
        "outputId": "3c5d7c3d-c30c-4f39-f35e-95bdf6b428e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-56-3145e7aac804>:51: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 01:39, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.556400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.122000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=120, training_loss=0.2962733010450999, metrics={'train_runtime': 100.2352, 'train_samples_per_second': 9.577, 'train_steps_per_second': 1.197, 'total_flos': 250851690086400.0, 'train_loss': 0.2962733010450999, 'epoch': 4.0})"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Évaluer le modèle sur le jeu de validation\n",
        "results = trainer.evaluate()\n",
        "\n",
        "# Affichage des métriques principales\n",
        "print(\"📊 Résultats de l'évaluation :\")\n",
        "print(f\"Accuracy : {results['eval_accuracy']:.4f}\")\n",
        "print(f\"F1-score : {results['eval_f1']:.4f}\")\n",
        "print(\"\\n📄 Rapport détaillé :\")\n",
        "print(results['eval_report'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "09H7xgrOefzu",
        "outputId": "6790db1f-a249-4538-c3a0-c8aa7f400e39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5/5 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Résultats de l'évaluation :\n",
            "Accuracy : 0.9414\n",
            "F1-score : 0.9414\n",
            "\n",
            "📄 Rapport détaillé :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     DISEASE       1.00      0.97      0.99       146\n",
            "        GENE       0.82      0.97      0.89        61\n",
            "     PROTEIN       0.95      0.90      0.92       116\n",
            "     SYMPTOM       0.00      0.00      0.00         1\n",
            "\n",
            "   micro avg       0.94      0.94      0.94       324\n",
            "   macro avg       0.69      0.71      0.70       324\n",
            "weighted avg       0.94      0.94      0.94       324\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 📊 Évaluation sur le jeu de test\n",
        "test_results = trainer.evaluate(eval_dataset=test_dataset)\n",
        "\n",
        "# 📋 Affichage des métriques\n",
        "print(\"📊 Résultats sur le jeu de test :\")\n",
        "print(f\"Accuracy : {test_results['eval_accuracy']:.4f}\")\n",
        "print(f\"F1-score : {test_results['eval_f1']:.4f}\")\n",
        "print(\"\\n📄 Rapport détaillé :\")\n",
        "print(test_results['eval_report'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "go2oPHf2ejSJ",
        "outputId": "d58bc3e4-d51a-4233-b99e-a650fa758514"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='15' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5/5 00:27]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Résultats sur le jeu de test :\n",
            "Accuracy : 0.9706\n",
            "F1-score : 0.9706\n",
            "\n",
            "📄 Rapport détaillé :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     DISEASE       0.95      1.00      0.98       105\n",
            "        GENE       0.98      0.92      0.95        59\n",
            "     PROTEIN       0.98      0.97      0.98       107\n",
            "     SYMPTOM       1.00      1.00      1.00         1\n",
            "\n",
            "   micro avg       0.97      0.97      0.97       272\n",
            "   macro avg       0.98      0.97      0.98       272\n",
            "weighted avg       0.97      0.97      0.97       272\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "source_dir = \"/content\"\n",
        "target_dir = \"/content/drive/MyDrive/NLP_dernier_modification_09_06_75_12.5_12.5\"\n",
        "\n",
        "# Créer le dossier cible s’il n’existe pas\n",
        "os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "# Parcourir tous les fichiers/dossiers dans /content sauf /content/drive\n",
        "for item in os.listdir(source_dir):\n",
        "    src_path = os.path.join(source_dir, item)\n",
        "    dst_path = os.path.join(target_dir, item)\n",
        "\n",
        "    if item == \"drive\":\n",
        "        continue  # ⚠️ Ignorer le dossier Google Drive\n",
        "\n",
        "    try:\n",
        "        if os.path.isdir(src_path):\n",
        "            shutil.copytree(src_path, dst_path, dirs_exist_ok=True)\n",
        "        else:\n",
        "            shutil.copy2(src_path, dst_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Erreur en copiant {item} : {e}\")\n",
        "\n",
        "print(f\"✅ Tous les fichiers (sauf /drive) ont été copiés vers : {target_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ntnd6XPemqA",
        "outputId": "acc20d25-25fc-4f44-bcb9-f42399637bef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Tous les fichiers (sauf /drive) ont été copiés vers : /content/drive/MyDrive/NLP_dernier_modification_09_06_75_12.5_12.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "________________________________________________________________________"
      ],
      "metadata": {
        "id": "amAhZHLWeQpc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test d'abilation Confeguration de Model"
      ],
      "metadata": {
        "id": "MkpdYR3Tki-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tests d'Ablation pour NER BioBERT\n",
        "# Voici plusieurs variantes du modèle pour analyser l'impact de différents composants\n",
        "\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer\n",
        "import numpy as np\n",
        "from seqeval.metrics import classification_report, accuracy_score, f1_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Configuration de base\n",
        "model_name = \"dmis-lab/biobert-base-cased-v1.1\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "label_list = ['O', 'B-GENE', 'B-PROTEIN', 'B-DISEASE', 'B-SYMPTOM']\n",
        "label2id = {label: i for i, label in enumerate(label_list)}\n",
        "id2label = {i: label for label, i in label2id.items()}\n",
        "\n",
        "# ═══════════════════════════════════════════════════════════════════════════════\n",
        "# 🧪 TEST D'ABLATION 1: Modèle avec couches gelées (frozen layers)\n",
        "# ═══════════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "def create_frozen_model(num_frozen_layers=6):\n",
        "    \"\"\"Gèle les N premières couches de BioBERT\"\"\"\n",
        "    model = AutoModelForTokenClassification.from_pretrained(\n",
        "        model_name,\n",
        "        num_labels=len(label_list),\n",
        "        id2label=id2label,\n",
        "        label2id=label2id\n",
        "    )\n",
        "\n",
        "    # Geler les premières couches\n",
        "    for i, layer in enumerate(model.bert.encoder.layer):\n",
        "        if i < num_frozen_layers:\n",
        "            for param in layer.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    print(f\"✅ Modèle créé avec {num_frozen_layers} couches gelées\")\n",
        "    return model\n",
        "\n",
        "# ═══════════════════════════════════════════════════════════════════════════════\n",
        "# 🧪 TEST D'ABLATION 2: Modèle avec dropout modifié\n",
        "# ═══════════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "def create_high_dropout_model(dropout_rate=0.3):\n",
        "    \"\"\"Augmente le dropout pour tester la régularisation\"\"\"\n",
        "    model = AutoModelForTokenClassification.from_pretrained(\n",
        "        model_name,\n",
        "        num_labels=len(label_list),\n",
        "        id2label=id2label,\n",
        "        label2id=label2id,\n",
        "        hidden_dropout_prob=dropout_rate,\n",
        "        attention_probs_dropout_prob=dropout_rate\n",
        "    )\n",
        "    print(f\"✅ Modèle créé avec dropout = {dropout_rate}\")\n",
        "    return model\n",
        "\n",
        "# ═══════════════════════════════════════════════════════════════════════════════\n",
        "# 🧪 TEST D'ABLATION 3: Modèle avec tête de classification simplifiée\n",
        "# ═══════════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "class SimplifiedNERModel(nn.Module):\n",
        "    def __init__(self, base_model_name, num_labels):\n",
        "        super().__init__()\n",
        "        self.bert = AutoModelForTokenClassification.from_pretrained(base_model_name).bert\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        # Tête simplifiée : une seule couche linéaire au lieu de dropout + linear\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
        "        self.num_labels = num_labels\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        sequence_output = outputs[0]\n",
        "        sequence_output = self.dropout(sequence_output)\n",
        "        logits = self.classifier(sequence_output)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss(ignore_index=-100)\n",
        "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "\n",
        "        return {\"loss\": loss, \"logits\": logits}\n",
        "\n",
        "def create_simplified_model():\n",
        "    \"\"\"Crée un modèle avec une tête de classification simplifiée\"\"\"\n",
        "    model = SimplifiedNERModel(model_name, len(label_list))\n",
        "    print(\"✅ Modèle créé avec tête de classification simplifiée\")\n",
        "    return model\n",
        "\n",
        "# ═══════════════════════════════════════════════════════════════════════════════\n",
        "# 🧪 TEST D'ABLATION 4: Modèle sans pré-entraînement (poids aléatoires)\n",
        "# ═══════════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "def create_random_weights_model():\n",
        "    \"\"\"Initialise le modèle avec des poids aléatoires (pas de pré-entraînement)\"\"\"\n",
        "    from transformers import BertConfig\n",
        "\n",
        "    config = BertConfig.from_pretrained(model_name)\n",
        "    config.num_labels = len(label_list)\n",
        "\n",
        "    model = AutoModelForTokenClassification.from_config(config)\n",
        "    model.config.id2label = id2label\n",
        "    model.config.label2id = label2id\n",
        "\n",
        "    print(\"✅ Modèle créé avec poids aléatoires (sans pré-entraînement)\")\n",
        "    return model\n",
        "\n",
        "# ═══════════════════════════════════════════════════════════════════════════════\n",
        "# 🧪 TEST D'ABLATION 5: Modèle avec moins de couches d'attention\n",
        "# ═══════════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "def create_fewer_layers_model(num_layers=6):\n",
        "    \"\"\"Crée un modèle avec moins de couches transformer\"\"\"\n",
        "    from transformers import BertConfig\n",
        "\n",
        "    config = BertConfig.from_pretrained(model_name)\n",
        "    config.num_hidden_layers = num_layers  # Réduire de 12 à 6 couches\n",
        "    config.num_labels = len(label_list)\n",
        "\n",
        "    model = AutoModelForTokenClassification.from_config(config)\n",
        "    model.config.id2label = id2label\n",
        "    model.config.label2id = label2id\n",
        "\n",
        "    print(f\"✅ Modèle créé avec {num_layers} couches au lieu de 12\")\n",
        "    return model\n",
        "\n",
        "# ═══════════════════════════════════════════════════════════════════════════════\n",
        "# 🧪 FONCTION D'ENTRAÎNEMENT GÉNÉRALISÉE\n",
        "# ═══════════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "def train_ablation_model(model, train_dataset, val_dataset, test_dataset,\n",
        "                        experiment_name, epochs=4, lr=2e-5):\n",
        "    \"\"\"Entraîne et évalue un modèle d'ablation\"\"\"\n",
        "\n",
        "    # Métriques d'évaluation\n",
        "    def compute_metrics(p):\n",
        "        preds = np.argmax(p.predictions, axis=2)\n",
        "        labels = p.label_ids\n",
        "\n",
        "        true_predictions = [\n",
        "            [id2label[p] for (p, l) in zip(pred, label) if l != -100]\n",
        "            for pred, label in zip(preds, labels)\n",
        "        ]\n",
        "        true_labels = [\n",
        "            [id2label[l] for (p, l) in zip(pred, label) if l != -100]\n",
        "            for pred, label in zip(preds, labels)\n",
        "        ]\n",
        "\n",
        "        return {\n",
        "            \"accuracy\": accuracy_score(true_labels, true_predictions),\n",
        "            \"f1\": f1_score(true_labels, true_predictions),\n",
        "            \"report\": classification_report(true_labels, true_predictions, output_dict=False)\n",
        "        }\n",
        "\n",
        "    # Arguments d'entraînement\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f\"./ner_biobert_{experiment_name}\",\n",
        "        do_train=True,\n",
        "        do_eval=True,\n",
        "        per_device_train_batch_size=8,\n",
        "        per_device_eval_batch_size=8,\n",
        "        learning_rate=lr,\n",
        "        num_train_epochs=epochs,\n",
        "        weight_decay=0.01,\n",
        "        logging_dir=f\"./logs_{experiment_name}\",\n",
        "        logging_steps=50,\n",
        "        save_steps=500,\n",
        "        eval_steps=500,\n",
        "        save_total_limit=2,\n",
        "    )\n",
        "\n",
        "    # Entraînement\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        tokenizer=tokenizer,\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    print(f\"\\n🚀 Début de l'entraînement : {experiment_name}\")\n",
        "    trainer.train()\n",
        "\n",
        "    # Évaluation\n",
        "    val_results = trainer.evaluate()\n",
        "    test_results = trainer.evaluate(eval_dataset=test_dataset)\n",
        "\n",
        "    print(f\"\\n📊 Résultats {experiment_name}:\")\n",
        "    print(f\"Validation - Accuracy: {val_results['eval_accuracy']:.4f}, F1: {val_results['eval_f1']:.4f}\")\n",
        "    print(f\"Test - Accuracy: {test_results['eval_accuracy']:.4f}, F1: {test_results['eval_f1']:.4f}\")\n",
        "\n",
        "    return {\n",
        "        'experiment': experiment_name,\n",
        "        'val_accuracy': val_results['eval_accuracy'],\n",
        "        'val_f1': val_results['eval_f1'],\n",
        "        'test_accuracy': test_results['eval_accuracy'],\n",
        "        'test_f1': test_results['eval_f1']\n",
        "    }\n",
        "\n",
        "# ═══════════════════════════════════════════════════════════════════════════════\n",
        "# 🧪 EXEMPLE D'UTILISATION - TESTS D'ABLATION\n",
        "# ═══════════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "def run_ablation_study(train_dataset, val_dataset, test_dataset):\n",
        "    \"\"\"Lance tous les tests d'ablation\"\"\"\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # Test 1: Modèle de base (référence)\n",
        "    print(\"=\"*60)\n",
        "    print(\"🧪 TEST 1: Modèle de base (BioBERT complet)\")\n",
        "    print(\"=\"*60)\n",
        "    base_model = AutoModelForTokenClassification.from_pretrained(\n",
        "        model_name, num_labels=len(label_list), id2label=id2label, label2id=label2id\n",
        "    )\n",
        "    results.append(train_ablation_model(\n",
        "        base_model, train_dataset, val_dataset, test_dataset, \"baseline\"\n",
        "    ))\n",
        "\n",
        "    # Test 2: Couches gelées\n",
        "    print(\"=\"*60)\n",
        "    print(\"🧪 TEST 2: Modèle avec 6 couches gelées\")\n",
        "    print(\"=\"*60)\n",
        "    frozen_model = create_frozen_model(num_frozen_layers=6)\n",
        "    results.append(train_ablation_model(\n",
        "        frozen_model, train_dataset, val_dataset, test_dataset, \"frozen_6_layers\"\n",
        "    ))\n",
        "\n",
        "    # Test 3: Dropout élevé\n",
        "    print(\"=\"*60)\n",
        "    print(\"🧪 TEST 3: Modèle avec dropout élevé (0.3)\")\n",
        "    print(\"=\"*60)\n",
        "    high_dropout_model = create_high_dropout_model(dropout_rate=0.3)\n",
        "    results.append(train_ablation_model(\n",
        "        high_dropout_model, train_dataset, val_dataset, test_dataset, \"high_dropout\"\n",
        "    ))\n",
        "\n",
        "    # Test 4: Tête simplifiée\n",
        "    print(\"=\"*60)\n",
        "    print(\"🧪 TEST 4: Modèle avec tête de classification simplifiée\")\n",
        "    print(\"=\"*60)\n",
        "    simplified_model = create_simplified_model()\n",
        "    results.append(train_ablation_model(\n",
        "        simplified_model, train_dataset, val_dataset, test_dataset, \"simplified_head\"\n",
        "    ))\n",
        "\n",
        "    # Test 5: Poids aléatoires\n",
        "    print(\"=\"*60)\n",
        "    print(\"🧪 TEST 5: Modèle sans pré-entraînement (poids aléatoires)\")\n",
        "    print(\"=\"*60)\n",
        "    random_model = create_random_weights_model()\n",
        "    results.append(train_ablation_model(\n",
        "        random_model, train_dataset, val_dataset, test_dataset, \"random_weights\", epochs=5, lr=5e-5\n",
        "    ))\n",
        "\n",
        "    # Résumé des résultats\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"📊 RÉSUMÉ DES TESTS D'ABLATION\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"{'Expérience':<20} {'Val Acc':<10} {'Val F1':<10} {'Test Acc':<10} {'Test F1':<10}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    for result in results:\n",
        "        print(f\"{result['experiment']:<20} {result['val_accuracy']:<10.4f} {result['val_f1']:<10.4f} \"\n",
        "              f\"{result['test_accuracy']:<10.4f} {result['test_f1']:<10.4f}\")\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "S5m_HO94krWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ═══════════════════════════════════════════════════════════════════════════════\n",
        "# 🚀 LANCEMENT DES TESTS\n",
        "# ═══════════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "# Supposons que vous avez déjà vos datasets chargés\n",
        "# train_dataset = prepare_dataset_from_bio(\"path/to/train.bio\")\n",
        "# val_dataset = prepare_dataset_from_bio(\"path/to/val.bio\")\n",
        "# test_dataset = prepare_dataset_from_bio(\"path/to/test.bio\")\n",
        "\n",
        "train_dataset = prepare_dataset_from_bio(\"/content/abstracts07_06_bio_train_60_20_20.bio\")\n",
        "val_dataset   = prepare_dataset_from_bio(\"/content/abstracts07_06_bio_val_60_20_20.bio\")\n",
        "test_dataset  = prepare_dataset_from_bio(\"/content/abstracts07_06_bio_test_60_20_20.bio\")\n",
        "\n",
        "# Lancer l'étude d'ablation complète\n",
        "ablation_results = run_ablation_study(train_dataset, val_dataset, test_dataset)\n",
        "\n",
        "# OU lancer un test individuel, par exemple :\n",
        "# model = create_frozen_model(num_frozen_layers=8)\n",
        "# result = train_ablation_model(model, train_dataset, val_dataset, test_dataset, \"frozen_8_layers\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JosZfSGrkwOM",
        "outputId": "96b012ff-ac66-4573-e8db-d606160aa63d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "🧪 TEST 1: Modèle de base (BioBERT complet)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-73-991c9516662b>:172: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🚀 Début de l'entraînement : baseline\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='96' max='96' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [96/96 02:04, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.551100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [8/8 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Résultats baseline:\n",
            "Validation - Accuracy: 0.9092, F1: 0.9092\n",
            "Test - Accuracy: 0.9789, F1: 0.9789\n",
            "============================================================\n",
            "🧪 TEST 2: Modèle avec 6 couches gelées\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-73-991c9516662b>:172: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Modèle créé avec 6 couches gelées\n",
            "\n",
            "🚀 Début de l'entraînement : frozen_6_layers\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='96' max='96' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [96/96 01:50, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.700100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [8/8 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Résultats frozen_6_layers:\n",
            "Validation - Accuracy: 0.8866, F1: 0.8866\n",
            "Test - Accuracy: 0.9604, F1: 0.9604\n",
            "============================================================\n",
            "🧪 TEST 3: Modèle avec dropout élevé (0.3)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-73-991c9516662b>:172: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Modèle créé avec dropout = 0.3\n",
            "\n",
            "🚀 Début de l'entraînement : high_dropout\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='96' max='96' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [96/96 01:49, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.832700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [8/8 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Résultats high_dropout:\n",
            "Validation - Accuracy: 0.8761, F1: 0.8761\n",
            "Test - Accuracy: 0.9578, F1: 0.9578\n",
            "============================================================\n",
            "🧪 TEST 4: Modèle avec tête de classification simplifiée\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-73-991c9516662b>:172: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Modèle créé avec tête de classification simplifiée\n",
            "\n",
            "🚀 Début de l'entraînement : simplified_head\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='96' max='96' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [96/96 01:49, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.608500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [8/8 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Résultats simplified_head:\n",
            "Validation - Accuracy: 0.8743, F1: 0.8743\n",
            "Test - Accuracy: 0.9551, F1: 0.9551\n",
            "============================================================\n",
            "🧪 TEST 5: Modèle sans pré-entraînement (poids aléatoires)\n",
            "============================================================\n",
            "✅ Modèle créé avec poids aléatoires (sans pré-entraînement)\n",
            "\n",
            "🚀 Début de l'entraînement : random_weights\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-73-991c9516662b>:172: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 02:04, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.763500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.187500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [8/8 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Résultats random_weights:\n",
            "Validation - Accuracy: 0.8080, F1: 0.8080\n",
            "Test - Accuracy: 0.9129, F1: 0.9129\n",
            "\n",
            "================================================================================\n",
            "📊 RÉSUMÉ DES TESTS D'ABLATION\n",
            "================================================================================\n",
            "Expérience           Val Acc    Val F1     Test Acc   Test F1   \n",
            "--------------------------------------------------------------------------------\n",
            "baseline             0.9092     0.9092     0.9789     0.9789    \n",
            "frozen_6_layers      0.8866     0.8866     0.9604     0.9604    \n",
            "high_dropout         0.8761     0.8761     0.9578     0.9578    \n",
            "simplified_head      0.8743     0.8743     0.9551     0.9551    \n",
            "random_weights       0.8080     0.8080     0.9129     0.9129    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2eme modele"
      ],
      "metadata": {
        "id": "-uaKWuUFcBQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOTxJ3wid6Rx",
        "outputId": "cae41626-ffc7-43f5-b1cb-21a104f1f90a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.32.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers datasets\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "N9QdMxbRfcXH",
        "outputId": "d3c845d6-befa-4ef2-fd3b-8bc738397fc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.32.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fsspec, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 2.14.4\n",
            "    Uninstalling datasets-2.14.4:\n",
            "      Successfully uninstalled datasets-2.14.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.6.0 fsspec-2025.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "datasets"
                ]
              },
              "id": "d4aec095e11947c0845dbe4cf248d6bc"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_list = ['O', 'B-GENE', 'B-PROTEIN', 'B-DISEASE', 'B-SYMPTOM']\n",
        "label2id = {label: i for i, label in enumerate(label_list)}\n",
        "id2label = {i: label for label, i in label2id.items()}"
      ],
      "metadata": {
        "id": "RqJ5-3ZOfwti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kz6QnB0wgkk9",
        "outputId": "9cc3784c-3102-4061-f146-fc93fd496a35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_list = ['O', 'B-GENE', 'B-PROTEIN', 'B-DISEASE', 'B-SYMPTOM']\n",
        "label2id = {label: i for i, label in enumerate(label_list)}\n",
        "id2label = {i: label for label, i in label2id.items()}\n",
        "\n",
        "\n",
        "# 📄 Lire un fichier BIO et l'organiser par phrase\n",
        "def read_bio_file(filepath):\n",
        "    sentences = []\n",
        "    labels = []\n",
        "    current_tokens = []\n",
        "    current_labels = []\n",
        "\n",
        "    with open(filepath, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            if line.strip() == '':\n",
        "                if current_tokens:\n",
        "                    sentences.append(current_tokens)\n",
        "                    labels.append(current_labels)\n",
        "                    current_tokens = []\n",
        "                    current_labels = []\n",
        "            else:\n",
        "                splits = line.strip().split()\n",
        "                if len(splits) == 2:\n",
        "                    token, tag = splits\n",
        "                    current_tokens.append(token)\n",
        "                    current_labels.append(tag)\n",
        "\n",
        "        # Ajouter la dernière phrase si non vide\n",
        "        if current_tokens:\n",
        "            sentences.append(current_tokens)\n",
        "            labels.append(current_labels)\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "\n",
        "# ✂ Tokenisation + alignement des labels avec gestion du max_length\n",
        "#    et exclusion des tokens \"O\" (ignorés avec -100)\n",
        "def tokenize_and_align(sentences, tags, tokenizer):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        sentences,\n",
        "        is_split_into_words=True,\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        padding=\"max_length\",\n",
        "        return_tensors=None\n",
        "    )\n",
        "\n",
        "    aligned_labels = []\n",
        "    for i, label in enumerate(tags):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            elif word_idx != previous_word_idx:\n",
        "                tag = label[word_idx]\n",
        "                label_ids.append(label2id[tag] if tag != \"O\" else -100)\n",
        "            else:\n",
        "                label_ids.append(-100)\n",
        "            previous_word_idx = word_idx\n",
        "\n",
        "        aligned_labels.append(label_ids)\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = aligned_labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "\n",
        "# 📁 Préparer un Dataset HuggingFace depuis un fichier BIO\n",
        "def prepare_dataset_from_bio(filepath):\n",
        "    sents, tags = read_bio_file(filepath)\n",
        "    tokenized = tokenize_and_align(sents, tags, tokenizer)\n",
        "    return Dataset.from_dict(tokenized)"
      ],
      "metadata": {
        "id": "slp4XTmwhYR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_dataset = prepare_dataset_from_bio(\"/content/drive/MyDrive/NLP_dernier_modification_07_06/abstracts07_06_bio_train.bio\")\n",
        "#val_dataset   = prepare_dataset_from_bio(\"/content/drive/MyDrive/NLP_dernier_modification_07_06/abstracts07_06_bio_val.bio\")\n",
        "#test_dataset  = prepare_dataset_from_bio(\"/content/drive/MyDrive/NLP_dernier_modification_07_06/abstracts07_06_bio_test.bio\")\n",
        "\n",
        "# ✅ Créer les datasets avec les bons fichiers\n",
        "# ✅ Créer les datasets avec les bons fichiers\n",
        "# train_dataset = prepare_dataset_from_bio(\"/content/abstracts07_06_bio_train_60_20_20.bio\")\n",
        "# val_dataset   = prepare_dataset_from_bio(\"/content/abstracts07_06_bio_val_60_20_20.bio\")\n",
        "# test_dataset  = prepare_dataset_from_bio(\"/content/abstracts07_06_bio_test_60_20_20.bio\")\n",
        "\n",
        "# ✅ Créer les datasets avec les bons fichiers\n",
        "train_dataset = prepare_dataset_from_bio(\"/content/abstracts07_06_bio_train.bio\")\n",
        "val_dataset   = prepare_dataset_from_bio(\"/content/abstracts07_06_bio_val.bio\")\n",
        "test_dataset  = prepare_dataset_from_bio(\"/content/abstracts07_06_bio_test.bio\")"
      ],
      "metadata": {
        "id": "eumOSVH4geK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "__________________________________________________________"
      ],
      "metadata": {
        "id": "KqkP3hJRvfm7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer\n",
        "import numpy as np\n",
        "from seqeval.metrics import classification_report, accuracy_score, f1_score\n",
        "\n",
        "# 📌 Nom du modèle\n",
        "model_name = \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\"\n",
        "\n",
        "# Charger le tokenizer et le modèle\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=len(label_list),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")\n",
        "\n",
        "# Métriques NER\n",
        "def compute_metrics(p):\n",
        "    preds = np.argmax(p.predictions, axis=2)\n",
        "    labels = p.label_ids\n",
        "\n",
        "    true_predictions = [\n",
        "        [id2label[p] for (p, l) in zip(pred, label) if l != -100]\n",
        "        for pred, label in zip(preds, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [id2label[l] for (p, l) in zip(pred, label) if l != -100]\n",
        "        for pred, label in zip(preds, labels)\n",
        "    ]\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(true_labels, true_predictions),\n",
        "        \"f1\": f1_score(true_labels, true_predictions),\n",
        "        \"report\": classification_report(true_labels, true_predictions, output_dict=False)\n",
        "    }\n",
        "\n",
        "# ✅ Configuration d'entraînement\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./ner_pubmedbert\",\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    eval_steps=500,\n",
        "    save_steps=500,\n",
        "    save_total_limit=2,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=4,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=50,\n",
        ")\n",
        "\n",
        "\n",
        "# Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# 🚀 Entraînement\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "e4UB4Mfulb54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "outputId": "1aaf14cd-6c8f-4a95-8781-5d099cc2e848"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-28-fc4f0a1e73ae>:57: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [128/128 01:55, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.575800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.150900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=128, training_loss=0.2989308377727866, metrics={'train_runtime': 116.8177, 'train_samples_per_second': 8.766, 'train_steps_per_second': 1.096, 'total_flos': 267575136092160.0, 'train_loss': 0.2989308377727866, 'epoch': 4.0})"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "_______________________________________________________________________"
      ],
      "metadata": {
        "id": "6CX3ALzLwcgy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "print(transformers.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UfMqEmrcwwk",
        "outputId": "98a01885-5539-4bec-bb5d-f443d5f287e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.52.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Évaluer le modèle sur le jeu de validation\n",
        "results = trainer.evaluate()\n",
        "\n",
        "# Affichage des métriques principales\n",
        "print(\"📊 Résultats de l'évaluation :\")\n",
        "print(f\"Accuracy : {results['eval_accuracy']:.4f}\")\n",
        "print(f\"F1-score : {results['eval_f1']:.4f}\")\n",
        "print(\"\\n📄 Rapport détaillé :\")\n",
        "print(results['eval_report'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "-QJUBX86gOiK",
        "outputId": "967db925-2b6e-4d9c-b48b-9488b14c8835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4/4 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Résultats de l'évaluation :\n",
            "Accuracy : 0.9267\n",
            "F1-score : 0.9267\n",
            "\n",
            "📄 Rapport détaillé :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     DISEASE       0.99      0.96      0.98       103\n",
            "        GENE       0.90      0.86      0.88        63\n",
            "     PROTEIN       0.88      0.93      0.91       105\n",
            "     SYMPTOM       1.00      1.00      1.00         2\n",
            "\n",
            "   micro avg       0.93      0.93      0.93       273\n",
            "   macro avg       0.94      0.94      0.94       273\n",
            "weighted avg       0.93      0.93      0.93       273\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 📊 Évaluation sur le jeu de test\n",
        "test_results = trainer.evaluate(eval_dataset=test_dataset)\n",
        "\n",
        "# 📋 Affichage des métriques\n",
        "print(\"📊 Résultats sur le jeu de test :\")\n",
        "print(f\"Accuracy : {test_results['eval_accuracy']:.4f}\")\n",
        "print(f\"F1-score : {test_results['eval_f1']:.4f}\")\n",
        "print(\"\\n📄 Rapport détaillé :\")\n",
        "print(test_results['eval_report'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "9XkXFC1fiEhW",
        "outputId": "abb3dc1d-3280-4443-c4ed-de54117ddea6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4/4 00:06]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Résultats sur le jeu de test :\n",
            "Accuracy : 0.9585\n",
            "F1-score : 0.9585\n",
            "\n",
            "📄 Rapport détaillé :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     DISEASE       0.99      0.99      0.99       120\n",
            "        GENE       0.93      0.95      0.94        66\n",
            "     PROTEIN       0.94      0.92      0.93        78\n",
            "     SYMPTOM       0.00      0.00      0.00         1\n",
            "\n",
            "   micro avg       0.96      0.96      0.96       265\n",
            "   macro avg       0.71      0.72      0.72       265\n",
            "weighted avg       0.96      0.96      0.96       265\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__________________________________________________________________"
      ],
      "metadata": {
        "id": "GF_p1july2dI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3 eme modele**"
      ],
      "metadata": {
        "id": "vq83bxb4jNEg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer\n",
        "import numpy as np\n",
        "from seqeval.metrics import classification_report, accuracy_score, f1_score\n",
        "\n",
        "# 📌 Nom du modèle SapBERT\n",
        "model_name = \"cambridgeltl/SapBERT-from-PubMedBERT-fulltext\"\n",
        "\n",
        "# Charger le tokenizer et le modèle\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=len(label_list),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")\n",
        "\n",
        "# 🔍 Métriques de NER\n",
        "def compute_metrics(p):\n",
        "    preds = np.argmax(p.predictions, axis=2)\n",
        "    labels = p.label_ids\n",
        "\n",
        "    true_predictions = [\n",
        "        [id2label[p] for (p, l) in zip(pred, label) if l != -100]\n",
        "        for pred, label in zip(preds, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [id2label[l] for (p, l) in zip(pred, label) if l != -100]\n",
        "        for pred, label in zip(preds, labels)\n",
        "    ]\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(true_labels, true_predictions),\n",
        "        \"f1\": f1_score(true_labels, true_predictions),\n",
        "        \"report\": classification_report(true_labels, true_predictions, output_dict=False)\n",
        "    }\n",
        "\n",
        "# ✅ Configuration d'entraînement\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./ner_sapbert\",\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    eval_steps=500,\n",
        "    save_steps=500,\n",
        "    save_total_limit=2,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=4,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=50,\n",
        ")\n",
        "\n",
        "# ⚙️ Trainer HuggingFace\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# 🚀 Lancer l'entraînement\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "9hFFkycejS5I",
        "outputId": "1964430f-914c-4be4-df2b-a472b2f44c4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at cambridgeltl/SapBERT-from-PubMedBERT-fulltext and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-22-bcb7a37bf3d4>:56: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [128/128 01:46, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.133200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.696900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=128, training_loss=0.8190451115369797, metrics={'train_runtime': 106.9887, 'train_samples_per_second': 9.571, 'train_steps_per_second': 1.196, 'total_flos': 267575136092160.0, 'train_loss': 0.8190451115369797, 'epoch': 4.0})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Évaluer le modèle sur le jeu de validation\n",
        "results = trainer.evaluate()\n",
        "\n",
        "# Affichage des métriques principales\n",
        "print(\"📊 Résultats de l'évaluation :\")\n",
        "print(f\"Accuracy : {results['eval_accuracy']:.4f}\")\n",
        "print(f\"F1-score : {results['eval_f1']:.4f}\")\n",
        "print(\"\\n📄 Rapport détaillé :\")\n",
        "print(results['eval_report'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "ESOJbJMVj3e3",
        "outputId": "083c28b3-4c18-4337-fa86-67789b92b4c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4/4 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Résultats de l'évaluation :\n",
            "Accuracy : 0.7889\n",
            "F1-score : 0.7889\n",
            "\n",
            "📄 Rapport détaillé :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     DISEASE       0.89      0.91      0.90       127\n",
            "        GENE       0.86      0.48      0.62        67\n",
            "     PROTEIN       0.63      0.92      0.75        71\n",
            "     SYMPTOM       0.00      0.00      0.00         5\n",
            "\n",
            "   micro avg       0.79      0.79      0.79       270\n",
            "   macro avg       0.60      0.58      0.57       270\n",
            "weighted avg       0.80      0.79      0.77       270\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 📊 Évaluation sur le jeu de test\n",
        "test_results = trainer.evaluate(eval_dataset=test_dataset)\n",
        "\n",
        "# 📋 Affichage des métriques\n",
        "print(\"📊 Résultats sur le jeu de test :\")\n",
        "print(f\"Accuracy : {test_results['eval_accuracy']:.4f}\")\n",
        "print(f\"F1-score : {test_results['eval_f1']:.4f}\")\n",
        "print(\"\\n📄 Rapport détaillé :\")\n",
        "print(test_results['eval_report'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "dZ_-KIk0lU9W",
        "outputId": "a3ecc165-6a3a-43d8-c88d-ed87eb76227f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4/4 01:16]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Résultats sur le jeu de test :\n",
            "Accuracy : 0.7438\n",
            "F1-score : 0.7438\n",
            "\n",
            "📄 Rapport détaillé :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     DISEASE       0.82      0.96      0.89       121\n",
            "        GENE       0.58      0.32      0.41        60\n",
            "     PROTEIN       0.68      0.82      0.74        87\n",
            "     SYMPTOM       1.00      0.23      0.38        13\n",
            "\n",
            "   micro avg       0.74      0.74      0.74       281\n",
            "   macro avg       0.77      0.58      0.60       281\n",
            "weighted avg       0.73      0.74      0.72       281\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "geykiFirmqUA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}